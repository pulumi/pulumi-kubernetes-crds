// *** WARNING: this file was generated by crd2pulumi. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

import {ObjectMeta} from "../meta/v1";

export namespace kafka {
    export namespace v1alpha1 {
        /**
         * The specification of the Kafka Bridge.
         */
        export interface KafkaBridgeSpec {
            /**
             * Authentication configuration for connecting to the cluster.
             */
            authentication?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthentication;
            /**
             * A list of host:port pairs for establishing the initial connection to the Kafka cluster.
             */
            bootstrapServers: string;
            /**
             * Kafka consumer related configuration.
             */
            consumer?: outputs.kafka.v1alpha1.KafkaBridgeSpecConsumer;
            /**
             * Enable the metrics for the Kafka Bridge. Default is false.
             */
            enableMetrics?: boolean;
            /**
             * The HTTP related configuration.
             */
            http?: outputs.kafka.v1alpha1.KafkaBridgeSpecHttp;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * **Currently not supported** JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1alpha1.KafkaBridgeSpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1alpha1.KafkaBridgeSpecLivenessProbe;
            /**
             * Logging configuration for Kafka Bridge.
             */
            logging?: outputs.kafka.v1alpha1.KafkaBridgeSpecLogging;
            /**
             * Kafka producer related configuration.
             */
            producer?: outputs.kafka.v1alpha1.KafkaBridgeSpecProducer;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1alpha1.KafkaBridgeSpecReadinessProbe;
            /**
             * The number of pods in the `Deployment`.
             */
            replicas?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1alpha1.KafkaBridgeSpecResources;
            /**
             * Template for Kafka Bridge resources. The template allows users to specify how is the `Deployment` and `Pods` generated.
             */
            template?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplate;
            /**
             * TLS configuration for connecting Kafka Bridge to the cluster.
             */
            tls?: outputs.kafka.v1alpha1.KafkaBridgeSpecTls;
            /**
             * The configuration of tracing in Kafka Bridge.
             */
            tracing?: outputs.kafka.v1alpha1.KafkaBridgeSpecTracing;
        }

        /**
         * Authentication configuration for connecting to the cluster.
         */
        export interface KafkaBridgeSpecAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1alpha1.KafkaBridgeSpecAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaBridgeSpecAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaBridgeSpecAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaBridgeSpecAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaBridgeSpecAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaBridgeSpecAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaBridgeSpecAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Kafka consumer related configuration.
         */
        export interface KafkaBridgeSpecConsumer {
            /**
             * The Kafka consumer configuration used for consumer instances created by the bridge. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security. (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
        }

        /**
         * The HTTP related configuration.
         */
        export interface KafkaBridgeSpecHttp {
            /**
             * CORS configuration for the HTTP Bridge.
             */
            cors?: outputs.kafka.v1alpha1.KafkaBridgeSpecHttpCors;
            /**
             * The port which is the server listening on.
             */
            port?: number;
        }

        /**
         * CORS configuration for the HTTP Bridge.
         */
        export interface KafkaBridgeSpecHttpCors {
            /**
             * List of allowed HTTP methods.
             */
            allowedMethods: string[];
            /**
             * List of allowed origins. Java regular expressions can be used.
             */
            allowedOrigins: string[];
        }

        /**
         * **Currently not supported** JVM Options for pods.
         */
        export interface KafkaBridgeSpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1alpha1.KafkaBridgeSpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaBridgeSpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaBridgeSpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka Bridge.
         */
        export interface KafkaBridgeSpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Kafka producer related configuration.
         */
        export interface KafkaBridgeSpecProducer {
            /**
             * The Kafka producer configuration used for producer instances created by the bridge. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security. (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaBridgeSpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaBridgeSpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for Kafka Bridge resources. The template allows users to specify how is the `Deployment` and `Pods` generated.
         */
        export interface KafkaBridgeSpecTemplate {
            /**
             * Template for Kafka Bridge API `Service`.
             */
            apiService?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateApiService;
            /**
             * Template for the Kafka Bridge container.
             */
            bridgeContainer?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateBridgeContainer;
            /**
             * Template for Kafka Bridge `Deployment`.
             */
            deployment?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateDeployment;
            /**
             * Template for Kafka Bridge `Pods`.
             */
            pod?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePod;
            /**
             * Template for Kafka Bridge `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka Bridge API `Service`.
         */
        export interface KafkaBridgeSpecTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaBridgeSpecTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka Bridge container.
         */
        export interface KafkaBridgeSpecTemplateBridgeContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateBridgeContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateBridgeContainerSecurityContext;
        }

        export interface KafkaBridgeSpecTemplateBridgeContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaBridgeSpecTemplateBridgeContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateBridgeContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateBridgeContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateBridgeContainerSecurityContextWindowsOptions;
        }

        export interface KafkaBridgeSpecTemplateBridgeContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaBridgeSpecTemplateBridgeContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaBridgeSpecTemplateBridgeContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Bridge `Deployment`.
         */
        export interface KafkaBridgeSpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaBridgeSpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka Bridge `Pods`.
         */
        export interface KafkaBridgeSpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaBridgeSpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaBridgeSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka Bridge `PodDisruptionBudget`.
         */
        export interface KafkaBridgeSpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaBridgeSpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaBridgeSpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaBridgeSpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaBridgeSpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaBridgeSpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1alpha1.KafkaBridgeSpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaBridgeSpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaBridgeSpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaBridgeSpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaBridgeSpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * TLS configuration for connecting Kafka Bridge to the cluster.
         */
        export interface KafkaBridgeSpecTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1alpha1.KafkaBridgeSpecTlsTrustedCertificates[];
        }

        export interface KafkaBridgeSpecTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * The configuration of tracing in Kafka Bridge.
         */
        export interface KafkaBridgeSpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of the Kafka Bridge.
         */
        export interface KafkaBridgeStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1alpha1.KafkaBridgeStatusConditions[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
            /**
             * The URL at which external client applications can access the Kafka Bridge.
             */
            url?: string;
        }

        export interface KafkaBridgeStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        /**
         * The specification of the Kafka Connector.
         */
        export interface KafkaConnectorSpec {
            /**
             * The Class for the Kafka Connector.
             */
            class?: string;
            /**
             * The Kafka Connector configuration. The following properties cannot be set: connector.class, tasks.max.
             */
            config?: {[key: string]: any};
            /**
             * Whether the connector should be paused. Defaults to false.
             */
            pause?: boolean;
            /**
             * The maximum number of tasks for the Kafka Connector.
             */
            tasksMax?: number;
        }

        /**
         * The status of the Kafka Connector.
         */
        export interface KafkaConnectorStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1alpha1.KafkaConnectorStatusConditions[];
            /**
             * The connector status, as reported by the Kafka Connect REST API.
             */
            connectorStatus?: {[key: string]: any};
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The maximum number of tasks for the Kafka Connector.
             */
            tasksMax?: number;
        }

        export interface KafkaConnectorStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        /**
         * The specification of the Kafka MirrorMaker 2.0 cluster.
         */
        export interface KafkaMirrorMaker2Spec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinity;
            /**
             * Kafka clusters for mirroring.
             */
            clusters?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClusters[];
            /**
             * The cluster alias used for Kafka Connect. The alias must match a cluster in the list at `spec.clusters`.
             */
            connectCluster: string;
            /**
             * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
             */
            externalConfiguration?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfiguration;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecLivenessProbe;
            /**
             * Logging configuration for Kafka Connect.
             */
            logging?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the MirrorMaker 2.0 connectors.
             */
            mirrors?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecMirrors[];
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecReadinessProbe;
            /**
             * The number of pods in the Kafka Connect group.
             */
            replicas?: number;
            /**
             * The maximum limits for CPU and memory resources and the requested initial resources.
             */
            resources?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecResources;
            /**
             * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
             */
            template?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplate;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTolerations[];
            /**
             * The configuration of tracing in Kafka Connect.
             */
            tracing?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTracing;
            /**
             * The Kafka Connect version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaMirrorMaker2SpecAffinity {
            nodeAffinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinity;
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecClusters {
            /**
             * Alias used to reference the Kafka cluster.
             */
            alias: string;
            /**
             * Authentication configuration for connecting to the cluster.
             */
            authentication?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthentication;
            /**
             * A comma-separated list of `host:port` pairs for establishing the connection to the Kafka cluster.
             */
            bootstrapServers: string;
            /**
             * The MirrorMaker 2.0 cluster config. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * TLS configuration for connecting MirrorMaker 2.0 connectors to a cluster.
             */
            tls?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersTls;
        }

        /**
         * Authentication configuration for connecting to the cluster.
         */
        export interface KafkaMirrorMaker2SpecClustersAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaMirrorMaker2SpecClustersAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaMirrorMaker2SpecClustersAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaMirrorMaker2SpecClustersAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaMirrorMaker2SpecClustersAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaMirrorMaker2SpecClustersAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaMirrorMaker2SpecClustersAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * TLS configuration for connecting MirrorMaker 2.0 connectors to a cluster.
         */
        export interface KafkaMirrorMaker2SpecClustersTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecClustersTlsTrustedCertificates[];
        }

        export interface KafkaMirrorMaker2SpecClustersTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
         */
        export interface KafkaMirrorMaker2SpecExternalConfiguration {
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as environment variables.
             */
            env?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationEnv[];
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as volumes.
             */
            volumes?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationVolumes[];
        }

        export interface KafkaMirrorMaker2SpecExternalConfigurationEnv {
            /**
             * Name of the environment variable which will be passed to the Kafka Connect pods. The name of the environment variable cannot start with `KAFKA_` or `STRIMZI_`.
             */
            name: string;
            /**
             * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
             */
            valueFrom: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationEnvValueFrom;
        }

        /**
         * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
         */
        export interface KafkaMirrorMaker2SpecExternalConfigurationEnvValueFrom {
            /**
             * Refernce to a key in a ConfigMap.
             */
            configMapKeyRef?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationEnvValueFromConfigMapKeyRef;
            /**
             * Reference to a key in a Secret.
             */
            secretKeyRef?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationEnvValueFromSecretKeyRef;
        }

        /**
         * Refernce to a key in a ConfigMap.
         */
        export interface KafkaMirrorMaker2SpecExternalConfigurationEnvValueFromConfigMapKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        /**
         * Reference to a key in a Secret.
         */
        export interface KafkaMirrorMaker2SpecExternalConfigurationEnvValueFromSecretKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        export interface KafkaMirrorMaker2SpecExternalConfigurationVolumes {
            /**
             * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
             */
            configMap?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationVolumesConfigMap;
            /**
             * Name of the volume which will be added to the Kafka Connect pods.
             */
            name: string;
            /**
             * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
             */
            secret?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationVolumesSecret;
        }

        /**
         * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaMirrorMaker2SpecExternalConfigurationVolumesConfigMap {
            defaultMode?: number;
            items?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationVolumesConfigMapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface KafkaMirrorMaker2SpecExternalConfigurationVolumesConfigMapItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaMirrorMaker2SpecExternalConfigurationVolumesSecret {
            defaultMode?: number;
            items?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecExternalConfigurationVolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface KafkaMirrorMaker2SpecExternalConfigurationVolumesSecretItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaMirrorMaker2SpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaMirrorMaker2SpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaMirrorMaker2SpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka Connect.
         */
        export interface KafkaMirrorMaker2SpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        export interface KafkaMirrorMaker2SpecMirrors {
            /**
             * The specification of the Kafka MirrorMaker 2.0 checkpoint connector.
             */
            checkpointConnector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecMirrorsCheckpointConnector;
            /**
             * A regular expression matching the consumer groups to exclude from mirroring. Comma-separated lists are also supported.
             */
            groupsBlacklistPattern?: string;
            /**
             * A regular expression matching the consumer groups to be mirrored. Comma-separated lists are also supported.
             */
            groupsPattern?: string;
            /**
             * The specification of the Kafka MirrorMaker 2.0 heartbeat connector.
             */
            heartbeatConnector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecMirrorsHeartbeatConnector;
            /**
             * The alias of the source cluster used by the Kafka MirrorMaker 2.0 connectors. The alias must match a cluster in the list at `spec.clusters`.
             */
            sourceCluster: string;
            /**
             * The specification of the Kafka MirrorMaker 2.0 source connector.
             */
            sourceConnector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecMirrorsSourceConnector;
            /**
             * The alias of the target cluster used by the Kafka MirrorMaker 2.0 connectors. The alias must match a cluster in the list at `spec.clusters`.
             */
            targetCluster: string;
            /**
             * A regular expression matching the topics to exclude from mirroring. Comma-separated lists are also supported.
             */
            topicsBlacklistPattern?: string;
            /**
             * A regular expression matching the topics to be mirrored, for example, "topic1\|topic2\|topic3". Comma-separated lists are also supported.
             */
            topicsPattern?: string;
        }

        /**
         * The specification of the Kafka MirrorMaker 2.0 checkpoint connector.
         */
        export interface KafkaMirrorMaker2SpecMirrorsCheckpointConnector {
            /**
             * The Kafka Connector configuration. The following properties cannot be set: connector.class, tasks.max.
             */
            config?: {[key: string]: any};
            /**
             * Whether the connector should be paused. Defaults to false.
             */
            pause?: boolean;
            /**
             * The maximum number of tasks for the Kafka Connector.
             */
            tasksMax?: number;
        }

        /**
         * The specification of the Kafka MirrorMaker 2.0 heartbeat connector.
         */
        export interface KafkaMirrorMaker2SpecMirrorsHeartbeatConnector {
            /**
             * The Kafka Connector configuration. The following properties cannot be set: connector.class, tasks.max.
             */
            config?: {[key: string]: any};
            /**
             * Whether the connector should be paused. Defaults to false.
             */
            pause?: boolean;
            /**
             * The maximum number of tasks for the Kafka Connector.
             */
            tasksMax?: number;
        }

        /**
         * The specification of the Kafka MirrorMaker 2.0 source connector.
         */
        export interface KafkaMirrorMaker2SpecMirrorsSourceConnector {
            /**
             * The Kafka Connector configuration. The following properties cannot be set: connector.class, tasks.max.
             */
            config?: {[key: string]: any};
            /**
             * Whether the connector should be paused. Defaults to false.
             */
            pause?: boolean;
            /**
             * The maximum number of tasks for the Kafka Connector.
             */
            tasksMax?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaMirrorMaker2SpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * The maximum limits for CPU and memory resources and the requested initial resources.
         */
        export interface KafkaMirrorMaker2SpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
         */
        export interface KafkaMirrorMaker2SpecTemplate {
            /**
             * Template for Kafka Connect API `Service`.
             */
            apiService?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateApiService;
            /**
             * Template for the Kafka Connect container.
             */
            connectContainer?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateConnectContainer;
            /**
             * Template for Kafka Connect `Deployment`.
             */
            deployment?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateDeployment;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateInitContainer;
            /**
             * Template for Kafka Connect `Pods`.
             */
            pod?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePod;
            /**
             * Template for Kafka Connect `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka Connect API `Service`.
         */
        export interface KafkaMirrorMaker2SpecTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMaker2SpecTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka Connect container.
         */
        export interface KafkaMirrorMaker2SpecTemplateConnectContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateConnectContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContext;
        }

        export interface KafkaMirrorMaker2SpecTemplateConnectContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplateConnectContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Deployment`.
         */
        export interface KafkaMirrorMaker2SpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMaker2SpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaMirrorMaker2SpecTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateInitContainerSecurityContext;
        }

        export interface KafkaMirrorMaker2SpecTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaMirrorMaker2SpecTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMaker2SpecTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Pods`.
         */
        export interface KafkaMirrorMaker2SpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaMirrorMaker2SpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka Connect `PodDisruptionBudget`.
         */
        export interface KafkaMirrorMaker2SpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaMirrorMaker2SpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaMirrorMaker2SpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMaker2SpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaMirrorMaker2SpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2SpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaMirrorMaker2SpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface KafkaMirrorMaker2SpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka Connect.
         */
        export interface KafkaMirrorMaker2SpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of the Kafka MirrorMaker 2.0 cluster.
         */
        export interface KafkaMirrorMaker2Status {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1alpha1.KafkaMirrorMaker2StatusConditions[];
            /**
             * The list of connector plugins available in this Kafka Connect deployment.
             */
            connectorPlugins?: outputs.kafka.v1alpha1.KafkaMirrorMaker2StatusConnectorPlugins[];
            /**
             * List of MirrorMaker 2.0 connector statuses, as reported by the Kafka Connect REST API.
             */
            connectors?: {[key: string]: any}[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
            /**
             * The URL of the REST API endpoint for managing and monitoring Kafka Connect connectors.
             */
            url?: string;
        }

        export interface KafkaMirrorMaker2StatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaMirrorMaker2StatusConnectorPlugins {
            /**
             * The class of the connector plugin.
             */
            class?: string;
            /**
             * The type of the connector plugin. The available types are `sink` and `source`.
             */
            type?: string;
            /**
             * The version of the connector plugin.
             */
            version?: string;
        }

        /**
         * The specification of the Kafka rebalance.
         */
        export interface KafkaRebalanceSpec {
            /**
             * The upper bound of ongoing partition replica movements between disks within each broker. Default is 2.
             */
            concurrentIntraBrokerPartitionMovements?: number;
            /**
             * The upper bound of ongoing partition leadership movements. Default is 1000.
             */
            concurrentLeaderMovements?: number;
            /**
             * The upper bound of ongoing partition replica movements going into/out of each broker. Default is 5.
             */
            concurrentPartitionMovementsPerBroker?: number;
            /**
             * A regular expression where any matching topics will be excluded from the calculation of optimization proposals. This expression will be parsed by the java.util.regex.Pattern class; for more information on the supported formar consult the documentation for that class.
             */
            excludedTopics?: string;
            /**
             * A list of goals, ordered by decreasing priority, to use for generating and executing the rebalance proposal. The supported goals are available at https://github.com/linkedin/cruise-control#goals. If an empty goals list is provided, the goals declared in the default.goals Cruise Control configuration parameter are used.
             */
            goals?: string[];
            /**
             * A list of strategy class names used to determine the execution order for the replica movements in the generated optimization proposal. By default BaseReplicaMovementStrategy is used, which will execute the replica movements in the order that they were generated.
             */
            replicaMovementStrategies?: string[];
            /**
             * The upper bound, in bytes per second, on the bandwidth used to move replicas. There is no limit by default.
             */
            replicationThrottle?: number;
            /**
             * Whether to allow the hard goals specified in the Kafka CR to be skipped in optimization proposal generation. This can be useful when some of those hard goals are preventing a balance solution being found. Default is false.
             */
            skipHardGoalCheck?: boolean;
        }

        /**
         * The status of the Kafka rebalance.
         */
        export interface KafkaRebalanceStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1alpha1.KafkaRebalanceStatusConditions[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * A JSON object describing the optimization result.
             */
            optimizationResult?: {[key: string]: any};
            /**
             * The session identifier for requests to Cruise Control pertaining to this KafkaRebalance resource. This is used by the Kafka Rebalance operator to track the status of ongoing rebalancing operations.
             */
            sessionId?: string;
        }

        export interface KafkaRebalanceStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

    }

    export namespace v1beta1 {
        /**
         * The specification of the Kafka Connect Source-to-Image (S2I) cluster.
         */
        export interface KafkaConnectS2ISpec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinity;
            /**
             * Authentication configuration for Kafka Connect.
             */
            authentication?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthentication;
            /**
             * Bootstrap servers to connect to. This should be given as a comma separated list of _<hostname>_:_<port>_ pairs.
             */
            bootstrapServers: string;
            /**
             * CPU and memory resources to reserve.
             */
            buildResources?: outputs.kafka.v1beta1.KafkaConnectS2ISpecBuildResources;
            /**
             * The image of the init container used for initializing the `client.rack`.
             */
            clientRackInitImage?: string;
            /**
             * The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
             */
            externalConfiguration?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfiguration;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * When true this configures the source repository with the 'Local' reference policy and an import policy that accepts insecure source tags.
             */
            insecureSourceRepository?: boolean;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaConnectS2ISpecLivenessProbe;
            /**
             * Logging configuration for Kafka Connect.
             */
            logging?: outputs.kafka.v1beta1.KafkaConnectS2ISpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the node label which will be used as the client.rack consumer configuration.
             */
            rack?: outputs.kafka.v1beta1.KafkaConnectS2ISpecRack;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaConnectS2ISpecReadinessProbe;
            /**
             * The number of pods in the Kafka Connect group.
             */
            replicas?: number;
            /**
             * The maximum limits for CPU and memory resources and the requested initial resources.
             */
            resources?: outputs.kafka.v1beta1.KafkaConnectS2ISpecResources;
            /**
             * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplate;
            /**
             * TLS configuration.
             */
            tls?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTls;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTolerations[];
            /**
             * The configuration of tracing in Kafka Connect.
             */
            tracing?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTracing;
            /**
             * The Kafka Connect version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectS2ISpecAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinity;
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Authentication configuration for Kafka Connect.
         */
        export interface KafkaConnectS2ISpecAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaConnectS2ISpecAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaConnectS2ISpecAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaConnectS2ISpecAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaConnectS2ISpecAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaConnectS2ISpecAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaConnectS2ISpecAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaConnectS2ISpecAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaConnectS2ISpecBuildResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
         */
        export interface KafkaConnectS2ISpecExternalConfiguration {
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as environment variables.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnv[];
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as volumes.
             */
            volumes?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumes[];
        }

        export interface KafkaConnectS2ISpecExternalConfigurationEnv {
            /**
             * Name of the environment variable which will be passed to the Kafka Connect pods. The name of the environment variable cannot start with `KAFKA_` or `STRIMZI_`.
             */
            name: string;
            /**
             * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
             */
            valueFrom: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnvValueFrom;
        }

        /**
         * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationEnvValueFrom {
            /**
             * Refernce to a key in a ConfigMap.
             */
            configMapKeyRef?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnvValueFromConfigMapKeyRef;
            /**
             * Reference to a key in a Secret.
             */
            secretKeyRef?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationEnvValueFromSecretKeyRef;
        }

        /**
         * Refernce to a key in a ConfigMap.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationEnvValueFromConfigMapKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        /**
         * Reference to a key in a Secret.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationEnvValueFromSecretKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectS2ISpecExternalConfigurationVolumes {
            /**
             * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
             */
            configMap?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesConfigMap;
            /**
             * Name of the volume which will be added to the Kafka Connect pods.
             */
            name: string;
            /**
             * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
             */
            secret?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesSecret;
        }

        /**
         * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationVolumesConfigMap {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesConfigMapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectS2ISpecExternalConfigurationVolumesConfigMapItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectS2ISpecExternalConfigurationVolumesSecret {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectS2ISpecExternalConfigurationVolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface KafkaConnectS2ISpecExternalConfigurationVolumesSecretItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaConnectS2ISpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaConnectS2ISpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaConnectS2ISpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaConnectS2ISpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka Connect.
         */
        export interface KafkaConnectS2ISpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of the node label which will be used as the client.rack consumer configuration.
         */
        export interface KafkaConnectS2ISpecRack {
            /**
             * A key that matches labels assigned to the Kubernetes cluster nodes. The value of the label is used to set the broker's `broker.rack` config.
             */
            topologyKey: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaConnectS2ISpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * The maximum limits for CPU and memory resources and the requested initial resources.
         */
        export interface KafkaConnectS2ISpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
         */
        export interface KafkaConnectS2ISpecTemplate {
            /**
             * Template for Kafka Connect API `Service`.
             */
            apiService?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateApiService;
            /**
             * Template for the Kafka Connect container.
             */
            connectContainer?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainer;
            /**
             * Template for Kafka Connect `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateDeployment;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainer;
            /**
             * Template for Kafka Connect `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePod;
            /**
             * Template for Kafka Connect `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka Connect API `Service`.
         */
        export interface KafkaConnectS2ISpecTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectS2ISpecTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka Connect container.
         */
        export interface KafkaConnectS2ISpecTemplateConnectContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContext;
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateConnectContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectS2ISpecTemplateConnectContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Deployment`.
         */
        export interface KafkaConnectS2ISpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectS2ISpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaConnectS2ISpecTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContext;
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectS2ISpecTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Pods`.
         */
        export interface KafkaConnectS2ISpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectS2ISpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka Connect `PodDisruptionBudget`.
         */
        export interface KafkaConnectS2ISpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaConnectS2ISpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaConnectS2ISpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectS2ISpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaConnectS2ISpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaConnectS2ISpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaConnectS2ISpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * TLS configuration.
         */
        export interface KafkaConnectS2ISpecTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaConnectS2ISpecTlsTrustedCertificates[];
        }

        export interface KafkaConnectS2ISpecTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaConnectS2ISpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka Connect.
         */
        export interface KafkaConnectS2ISpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of the Kafka Connect Source-to-Image (S2I) cluster.
         */
        export interface KafkaConnectS2IStatus {
            /**
             * The name of the build configuration.
             */
            buildConfigName?: string;
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaConnectS2IStatusConditions[];
            /**
             * The list of connector plugins available in this Kafka Connect deployment.
             */
            connectorPlugins?: outputs.kafka.v1beta1.KafkaConnectS2IStatusConnectorPlugins[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
            /**
             * The URL of the REST API endpoint for managing and monitoring Kafka Connect connectors.
             */
            url?: string;
        }

        export interface KafkaConnectS2IStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaConnectS2IStatusConnectorPlugins {
            /**
             * The class of the connector plugin.
             */
            class?: string;
            /**
             * The type of the connector plugin. The available types are `sink` and `source`.
             */
            type?: string;
            /**
             * The version of the connector plugin.
             */
            version?: string;
        }

        /**
         * The specification of the Kafka Connect cluster.
         */
        export interface KafkaConnectSpec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinity;
            /**
             * Authentication configuration for Kafka Connect.
             */
            authentication?: outputs.kafka.v1beta1.KafkaConnectSpecAuthentication;
            /**
             * Bootstrap servers to connect to. This should be given as a comma separated list of _<hostname>_:_<port>_ pairs.
             */
            bootstrapServers: string;
            /**
             * The image of the init container used for initializing the `client.rack`.
             */
            clientRackInitImage?: string;
            /**
             * The Kafka Connect configuration. Properties with the following prefixes cannot be set: ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
             */
            externalConfiguration?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfiguration;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaConnectSpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaConnectSpecLivenessProbe;
            /**
             * Logging configuration for Kafka Connect.
             */
            logging?: outputs.kafka.v1beta1.KafkaConnectSpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the node label which will be used as the client.rack consumer configuration.
             */
            rack?: outputs.kafka.v1beta1.KafkaConnectSpecRack;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaConnectSpecReadinessProbe;
            /**
             * The number of pods in the Kafka Connect group.
             */
            replicas?: number;
            /**
             * The maximum limits for CPU and memory resources and the requested initial resources.
             */
            resources?: outputs.kafka.v1beta1.KafkaConnectSpecResources;
            /**
             * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaConnectSpecTemplate;
            /**
             * TLS configuration.
             */
            tls?: outputs.kafka.v1beta1.KafkaConnectSpecTls;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectSpecTolerations[];
            /**
             * The configuration of tracing in Kafka Connect.
             */
            tracing?: outputs.kafka.v1beta1.KafkaConnectSpecTracing;
            /**
             * The Kafka Connect version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectSpecAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinity;
        }

        export interface KafkaConnectSpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Authentication configuration for Kafka Connect.
         */
        export interface KafkaConnectSpecAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaConnectSpecAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaConnectSpecAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaConnectSpecAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaConnectSpecAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaConnectSpecAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaConnectSpecAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaConnectSpecAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Pass data from Secrets or ConfigMaps to the Kafka Connect pods and use them to configure connectors.
         */
        export interface KafkaConnectSpecExternalConfiguration {
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as environment variables.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnv[];
            /**
             * Allows to pass data from Secret or ConfigMap to the Kafka Connect pods as volumes.
             */
            volumes?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumes[];
        }

        export interface KafkaConnectSpecExternalConfigurationEnv {
            /**
             * Name of the environment variable which will be passed to the Kafka Connect pods. The name of the environment variable cannot start with `KAFKA_` or `STRIMZI_`.
             */
            name: string;
            /**
             * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
             */
            valueFrom: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnvValueFrom;
        }

        /**
         * Value of the environment variable which will be passed to the Kafka Connect pods. It can be passed either as a reference to Secret or ConfigMap field. The field has to specify exactly one Secret or ConfigMap.
         */
        export interface KafkaConnectSpecExternalConfigurationEnvValueFrom {
            /**
             * Refernce to a key in a ConfigMap.
             */
            configMapKeyRef?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnvValueFromConfigMapKeyRef;
            /**
             * Reference to a key in a Secret.
             */
            secretKeyRef?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationEnvValueFromSecretKeyRef;
        }

        /**
         * Refernce to a key in a ConfigMap.
         */
        export interface KafkaConnectSpecExternalConfigurationEnvValueFromConfigMapKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        /**
         * Reference to a key in a Secret.
         */
        export interface KafkaConnectSpecExternalConfigurationEnvValueFromSecretKeyRef {
            key?: string;
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectSpecExternalConfigurationVolumes {
            /**
             * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
             */
            configMap?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesConfigMap;
            /**
             * Name of the volume which will be added to the Kafka Connect pods.
             */
            name: string;
            /**
             * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
             */
            secret?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesSecret;
        }

        /**
         * Reference to a key in a ConfigMap. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectSpecExternalConfigurationVolumesConfigMap {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesConfigMapItems[];
            name?: string;
            optional?: boolean;
        }

        export interface KafkaConnectSpecExternalConfigurationVolumesConfigMapItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * Reference to a key in a Secret. Exactly one Secret or ConfigMap has to be specified.
         */
        export interface KafkaConnectSpecExternalConfigurationVolumesSecret {
            defaultMode?: number;
            items?: outputs.kafka.v1beta1.KafkaConnectSpecExternalConfigurationVolumesSecretItems[];
            optional?: boolean;
            secretName?: string;
        }

        export interface KafkaConnectSpecExternalConfigurationVolumesSecretItems {
            key?: string;
            mode?: number;
            path?: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaConnectSpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaConnectSpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaConnectSpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaConnectSpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka Connect.
         */
        export interface KafkaConnectSpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of the node label which will be used as the client.rack consumer configuration.
         */
        export interface KafkaConnectSpecRack {
            /**
             * A key that matches labels assigned to the Kubernetes cluster nodes. The value of the label is used to set the broker's `broker.rack` config.
             */
            topologyKey: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaConnectSpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * The maximum limits for CPU and memory resources and the requested initial resources.
         */
        export interface KafkaConnectSpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for Kafka Connect and Kafka Connect S2I resources. The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.
         */
        export interface KafkaConnectSpecTemplate {
            /**
             * Template for Kafka Connect API `Service`.
             */
            apiService?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateApiService;
            /**
             * Template for the Kafka Connect container.
             */
            connectContainer?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainer;
            /**
             * Template for Kafka Connect `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateDeployment;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainer;
            /**
             * Template for Kafka Connect `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePod;
            /**
             * Template for Kafka Connect `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka Connect API `Service`.
         */
        export interface KafkaConnectSpecTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectSpecTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka Connect container.
         */
        export interface KafkaConnectSpecTemplateConnectContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContext;
        }

        export interface KafkaConnectSpecTemplateConnectContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectSpecTemplateConnectContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateConnectContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectSpecTemplateConnectContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectSpecTemplateConnectContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectSpecTemplateConnectContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Deployment`.
         */
        export interface KafkaConnectSpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectSpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaConnectSpecTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContext;
        }

        export interface KafkaConnectSpecTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaConnectSpecTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaConnectSpecTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaConnectSpecTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectSpecTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Connect `Pods`.
         */
        export interface KafkaConnectSpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaConnectSpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka Connect `PodDisruptionBudget`.
         */
        export interface KafkaConnectSpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaConnectSpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaConnectSpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaConnectSpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaConnectSpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaConnectSpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaConnectSpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaConnectSpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaConnectSpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaConnectSpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaConnectSpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * TLS configuration.
         */
        export interface KafkaConnectSpecTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaConnectSpecTlsTrustedCertificates[];
        }

        export interface KafkaConnectSpecTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaConnectSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka Connect.
         */
        export interface KafkaConnectSpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of the Kafka Connect cluster.
         */
        export interface KafkaConnectStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaConnectStatusConditions[];
            /**
             * The list of connector plugins available in this Kafka Connect deployment.
             */
            connectorPlugins?: outputs.kafka.v1beta1.KafkaConnectStatusConnectorPlugins[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
            /**
             * The URL of the REST API endpoint for managing and monitoring Kafka Connect connectors.
             */
            url?: string;
        }

        export interface KafkaConnectStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaConnectStatusConnectorPlugins {
            /**
             * The class of the connector plugin.
             */
            class?: string;
            /**
             * The type of the connector plugin. The available types are `sink` and `source`.
             */
            type?: string;
            /**
             * The version of the connector plugin.
             */
            version?: string;
        }

        /**
         * The specification of Kafka MirrorMaker.
         */
        export interface KafkaMirrorMakerSpec {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinity;
            /**
             * Configuration of source cluster.
             */
            consumer: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumer;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecLivenessProbe;
            /**
             * Logging configuration for MirrorMaker.
             */
            logging?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecLogging;
            /**
             * The Prometheus JMX Exporter configuration. See {JMXExporter} for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of target cluster.
             */
            producer: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducer;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecReadinessProbe;
            /**
             * The number of pods in the `Deployment`.
             */
            replicas: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecResources;
            /**
             * Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplate;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTolerations[];
            /**
             * The configuration of tracing in Kafka MirrorMaker.
             */
            tracing?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTracing;
            /**
             * The Kafka MirrorMaker version. Defaults to {DefaultKafkaVersion}. Consult the documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
            /**
             * List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. Mirroring two topics named A and B is achieved by using the whitelist `'A\|B'`. Or, as a special case, you can mirror all topics using the whitelist '*'. You can also specify multiple regular expressions separated by commas.
             */
            whitelist: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaMirrorMakerSpecAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinity;
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Configuration of source cluster.
         */
        export interface KafkaMirrorMakerSpecConsumer {
            /**
             * Authentication configuration for connecting to the cluster.
             */
            authentication?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthentication;
            /**
             * A list of host:port pairs for establishing the initial connection to the Kafka cluster.
             */
            bootstrapServers: string;
            /**
             * The MirrorMaker consumer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * A unique string that identifies the consumer group this consumer belongs to.
             */
            groupId: string;
            /**
             * Specifies the number of consumer stream threads to create.
             */
            numStreams?: number;
            /**
             * Specifies the offset auto-commit interval in ms. Default value is 60000.
             */
            offsetCommitInterval?: number;
            /**
             * TLS configuration for connecting MirrorMaker to the cluster.
             */
            tls?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerTls;
        }

        /**
         * Authentication configuration for connecting to the cluster.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaMirrorMakerSpecConsumerAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaMirrorMakerSpecConsumerAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * TLS configuration for connecting MirrorMaker to the cluster.
         */
        export interface KafkaMirrorMakerSpecConsumerTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecConsumerTlsTrustedCertificates[];
        }

        export interface KafkaMirrorMakerSpecConsumerTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaMirrorMakerSpecJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaMirrorMakerSpecJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaMirrorMakerSpecLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for MirrorMaker.
         */
        export interface KafkaMirrorMakerSpecLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of target cluster.
         */
        export interface KafkaMirrorMakerSpecProducer {
            /**
             * Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.
             */
            abortOnSendFailure?: boolean;
            /**
             * Authentication configuration for connecting to the cluster.
             */
            authentication?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthentication;
            /**
             * A list of host:port pairs for establishing the initial connection to the Kafka cluster.
             */
            bootstrapServers: string;
            /**
             * The MirrorMaker producer config. Properties with the following prefixes cannot be set: ssl., bootstrap.servers, sasl., security., interceptor.classes (with the exception of: ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols).
             */
            config?: {[key: string]: any};
            /**
             * TLS configuration for connecting MirrorMaker to the cluster.
             */
            tls?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerTls;
        }

        /**
         * Authentication configuration for connecting to the cluster.
         */
        export interface KafkaMirrorMakerSpecProducerAuthentication {
            /**
             * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
             */
            accessToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationAccessToken;
            /**
             * Configure whether access token should be treated as JWT. This should be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair.
             */
            certificateAndKey?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationCertificateAndKey;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Set or limit time-to-live of the access tokens to the specified number of seconds. This should be set if the authorization server returns opaque tokens.
             */
            maxTokenExpirySeconds?: number;
            /**
             * Reference to the `Secret` which holds the password.
             */
            passwordSecret?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationPasswordSecret;
            /**
             * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
             */
            refreshToken?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationRefreshToken;
            /**
             * OAuth scope to use when authenticating against the authorization server. Some authorization servers require this to be set. The possible values depend on how authorization server is configured. By default `scope` is not specified when doing the token endpoint request.
             */
            scope?: string;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerAuthenticationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authentication type. Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `plain` type uses SASL PLAIN Authentication. `oauth` type uses SASL OAUTHBEARER Authentication. The `tls` type uses TLS Client Authentication. The `tls` type is supported only over TLS connections.
             */
            type: string;
            /**
             * Username used for the authentication.
             */
            username?: string;
        }

        /**
         * Link to Kubernetes Secret containing the access token which was obtained from the authorization server.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationAccessToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationCertificateAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        /**
         * Reference to the `Secret` which holds the password.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationPasswordSecret {
            /**
             * The name of the key in the Secret under which the password is stored.
             */
            password: string;
            /**
             * The name of the Secret containing the password.
             */
            secretName: string;
        }

        /**
         * Link to Kubernetes Secret containing the refresh token which can be used to obtain access token from the authorization server.
         */
        export interface KafkaMirrorMakerSpecProducerAuthenticationRefreshToken {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaMirrorMakerSpecProducerAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * TLS configuration for connecting MirrorMaker to the cluster.
         */
        export interface KafkaMirrorMakerSpecProducerTls {
            /**
             * Trusted certificates for TLS connection.
             */
            trustedCertificates?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecProducerTlsTrustedCertificates[];
        }

        export interface KafkaMirrorMakerSpecProducerTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaMirrorMakerSpecReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaMirrorMakerSpecResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template to specify how Kafka MirrorMaker resources, `Deployments` and `Pods`, are generated.
         */
        export interface KafkaMirrorMakerSpecTemplate {
            /**
             * Template for Kafka MirrorMaker `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateDeployment;
            /**
             * Template for Kafka MirrorMaker container.
             */
            mirrorMakerContainer?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainer;
            /**
             * Template for Kafka MirrorMaker `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePod;
            /**
             * Template for Kafka MirrorMaker `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodDisruptionBudget;
        }

        /**
         * Template for Kafka MirrorMaker `Deployment`.
         */
        export interface KafkaMirrorMakerSpecTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMakerSpecTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka MirrorMaker container.
         */
        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContext;
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMakerSpecTemplateMirrorMakerContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka MirrorMaker `Pods`.
         */
        export interface KafkaMirrorMakerSpecTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaMirrorMakerSpecTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka MirrorMaker `PodDisruptionBudget`.
         */
        export interface KafkaMirrorMakerSpecTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaMirrorMakerSpecTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaMirrorMakerSpecTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaMirrorMakerSpecTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaMirrorMakerSpecTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaMirrorMakerSpecTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaMirrorMakerSpecTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaMirrorMakerSpecTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        export interface KafkaMirrorMakerSpecTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The configuration of tracing in Kafka MirrorMaker.
         */
        export interface KafkaMirrorMakerSpecTracing {
            /**
             * Type of the tracing used. Currently the only supported type is `jaeger` for Jaeger tracing.
             */
            type: string;
        }

        /**
         * The status of Kafka MirrorMaker.
         */
        export interface KafkaMirrorMakerStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaMirrorMakerStatusConditions[];
            /**
             * Label selector for pods providing this resource.
             */
            labelSelector?: string;
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The current number of pods being used to provide this resource.
             */
            replicas?: number;
        }

        export interface KafkaMirrorMakerStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        /**
         * The specification of the Kafka and ZooKeeper clusters, and Topic Operator.
         */
        export interface KafkaSpec {
            /**
             * Configuration of the clients certificate authority.
             */
            clientsCa?: outputs.kafka.v1beta1.KafkaSpecClientsCa;
            /**
             * Configuration of the cluster certificate authority.
             */
            clusterCa?: outputs.kafka.v1beta1.KafkaSpecClusterCa;
            /**
             * Configuration for Cruise Control deployment. Deploys a Cruise Control instance when specified.
             */
            cruiseControl?: outputs.kafka.v1beta1.KafkaSpecCruiseControl;
            /**
             * Configuration of the Entity Operator.
             */
            entityOperator?: outputs.kafka.v1beta1.KafkaSpecEntityOperator;
            /**
             * Configuration for JmxTrans. When the property is present a JmxTrans deployment is created for gathering JMX metrics from each Kafka broker. For more information see https://github.com/jmxtrans/jmxtrans[JmxTrans GitHub].
             */
            jmxTrans?: outputs.kafka.v1beta1.KafkaSpecJmxTrans;
            /**
             * Configuration of the Kafka cluster.
             */
            kafka: outputs.kafka.v1beta1.KafkaSpecKafka;
            /**
             * Configuration of the Kafka Exporter. Kafka Exporter can provide additional metrics, for example lag of consumer group at topic/partition.
             */
            kafkaExporter?: outputs.kafka.v1beta1.KafkaSpecKafkaExporter;
            /**
             * A list of time windows for maintenance tasks (that is, certificates renewal). Each time window is defined by a cron expression.
             */
            maintenanceTimeWindows?: string[];
            /**
             * Configuration of the Topic Operator.
             */
            topicOperator?: outputs.kafka.v1beta1.KafkaSpecTopicOperator;
            /**
             * Configuration of the ZooKeeper cluster.
             */
            zookeeper: outputs.kafka.v1beta1.KafkaSpecZookeeper;
        }

        /**
         * Configuration of the clients certificate authority.
         */
        export interface KafkaSpecClientsCa {
            /**
             * How should CA certificate expiration be handled when `generateCertificateAuthority=true`. The default is for a new CA certificate to be generated reusing the existing private key.
             */
            certificateExpirationPolicy?: string;
            /**
             * If true then Certificate Authority certificates will be generated automatically. Otherwise the user will need to provide a Secret with the CA certificate. Default is true.
             */
            generateCertificateAuthority?: boolean;
            /**
             * The number of days in the certificate renewal period. This is the number of days before the a certificate expires during which renewal actions may be performed. When `generateCertificateAuthority` is true, this will cause the generation of a new certificate. When `generateCertificateAuthority` is true, this will cause extra logging at WARN level about the pending certificate expiry. Default is 30.
             */
            renewalDays?: number;
            /**
             * The number of days generated certificates should be valid for. The default is 365.
             */
            validityDays?: number;
        }

        /**
         * Configuration of the cluster certificate authority.
         */
        export interface KafkaSpecClusterCa {
            /**
             * How should CA certificate expiration be handled when `generateCertificateAuthority=true`. The default is for a new CA certificate to be generated reusing the existing private key.
             */
            certificateExpirationPolicy?: string;
            /**
             * If true then Certificate Authority certificates will be generated automatically. Otherwise the user will need to provide a Secret with the CA certificate. Default is true.
             */
            generateCertificateAuthority?: boolean;
            /**
             * The number of days in the certificate renewal period. This is the number of days before the a certificate expires during which renewal actions may be performed. When `generateCertificateAuthority` is true, this will cause the generation of a new certificate. When `generateCertificateAuthority` is true, this will cause extra logging at WARN level about the pending certificate expiry. Default is 30.
             */
            renewalDays?: number;
            /**
             * The number of days generated certificates should be valid for. The default is 365.
             */
            validityDays?: number;
        }

        /**
         * Configuration for Cruise Control deployment. Deploys a Cruise Control instance when specified.
         */
        export interface KafkaSpecCruiseControl {
            /**
             * The Cruise Control `brokerCapacity` configuration.
             */
            brokerCapacity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlBrokerCapacity;
            /**
             * The Cruise Control configuration. For a full list of configuration options refer to https://github.com/linkedin/cruise-control/wiki/Configurations. Note that properties with the following prefixes cannot be set: bootstrap.servers, client.id, zookeeper., network., security., failed.brokers.zk.path,webserver.http., webserver.api.urlprefix, webserver.session.path, webserver.accesslog., two.step., request.reason.required,metric.reporter.sampler.bootstrap.servers, metric.reporter.topic, partition.metric.sample.store.topic, broker.metric.sample.store.topic,capacity.config.file, self.healing., anomaly.detection., ssl.
             */
            config?: {[key: string]: any};
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for the Cruise Control container.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlJvmOptions;
            /**
             * Pod liveness checking for the Cruise Control container.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlLivenessProbe;
            /**
             * Logging configuration (log4j1) for Cruise Control.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecCruiseControlLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Pod readiness checking for the Cruise Control container.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlReadinessProbe;
            /**
             * CPU and memory resources to reserve for the Cruise Control container.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecCruiseControlResources;
            /**
             * Template to specify how Cruise Control resources, `Deployments` and `Pods`, are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplate;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecar;
        }

        /**
         * The Cruise Control `brokerCapacity` configuration.
         */
        export interface KafkaSpecCruiseControlBrokerCapacity {
            /**
             * Broker capacity for CPU resource utilization as a percentage (0 - 100).
             */
            cpuUtilization?: number;
            /**
             * Broker capacity for disk in bytes, for example, 100Gi.
             */
            disk?: string;
            /**
             * Broker capacity for inbound network throughput in bytes per second, for example, 10000KB/s.
             */
            inboundNetwork?: string;
            /**
             * Broker capacity for outbound network throughput in bytes per second, for example 10000KB/s.
             */
            outboundNetwork?: string;
        }

        /**
         * JVM Options for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecCruiseControlJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecCruiseControlJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration (log4j1) for Cruise Control.
         */
        export interface KafkaSpecCruiseControlLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template to specify how Cruise Control resources, `Deployments` and `Pods`, are generated.
         */
        export interface KafkaSpecCruiseControlTemplate {
            /**
             * Template for Cruise Control API `Service`.
             */
            apiService?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateApiService;
            /**
             * Template for the Cruise Control container.
             */
            cruiseControlContainer?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainer;
            /**
             * Template for Cruise Control `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateDeployment;
            /**
             * Template for Cruise Control `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePod;
            /**
             * Template for Cruise Control `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodDisruptionBudget;
            /**
             * Template for the Cruise Control TLS sidecar container.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainer;
        }

        /**
         * Template for Cruise Control API `Service`.
         */
        export interface KafkaSpecCruiseControlTemplateApiService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateApiServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecCruiseControlTemplateApiServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Cruise Control container.
         */
        export interface KafkaSpecCruiseControlTemplateCruiseControlContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContext;
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecCruiseControlTemplateCruiseControlContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Cruise Control `Deployment`.
         */
        export interface KafkaSpecCruiseControlTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecCruiseControlTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Cruise Control `Pods`.
         */
        export interface KafkaSpecCruiseControlTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecCruiseControlTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Cruise Control `PodDisruptionBudget`.
         */
        export interface KafkaSpecCruiseControlTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaSpecCruiseControlTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaSpecCruiseControlTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecCruiseControlTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecCruiseControlTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecCruiseControlTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecCruiseControlTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for the Cruise Control TLS sidecar container.
         */
        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecCruiseControlTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecCruiseControlTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecCruiseControlTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecCruiseControlTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecCruiseControlTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecCruiseControlTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration of the Entity Operator.
         */
        export interface KafkaSpecEntityOperator {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinity;
            /**
             * Template for Entity Operator resources. The template allows users to specify how is the `Deployment` and `Pods` generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplate;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecar;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTolerations[];
            /**
             * Configuration of the Topic Operator.
             */
            topicOperator?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperator;
            /**
             * Configuration of the User Operator.
             */
            userOperator?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperator;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecEntityOperatorAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinity;
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Entity Operator resources. The template allows users to specify how is the `Deployment` and `Pods` generated.
         */
        export interface KafkaSpecEntityOperatorTemplate {
            /**
             * Template for Entity Operator `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateDeployment;
            /**
             * Template for Entity Operator `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePod;
            /**
             * Template for the Entity Operator TLS sidecar container.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainer;
            /**
             * Template for the Entity Topic Operator container.
             */
            topicOperatorContainer?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainer;
            /**
             * Template for the Entity User Operator container.
             */
            userOperatorContainer?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainer;
        }

        /**
         * Template for Entity Operator `Deployment`.
         */
        export interface KafkaSpecEntityOperatorTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecEntityOperatorTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Entity Operator `Pods`.
         */
        export interface KafkaSpecEntityOperatorTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecEntityOperatorTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecEntityOperatorTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecEntityOperatorTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecEntityOperatorTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for the Entity Operator TLS sidecar container.
         */
        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the Entity Topic Operator container.
         */
        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContext;
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplateTopicOperatorContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the Entity User Operator container.
         */
        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContext;
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecEntityOperatorTemplateUserOperatorContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecEntityOperatorTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecEntityOperatorTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecEntityOperatorTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecEntityOperatorTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        export interface KafkaSpecEntityOperatorTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Configuration of the Topic Operator.
         */
        export interface KafkaSpecEntityOperatorTopicOperator {
            /**
             * The image to use for the Topic Operator.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorLivenessProbe;
            /**
             * Logging configuration.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorLogging;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorReadinessProbe;
            /**
             * Interval between periodic reconciliations.
             */
            reconciliationIntervalSeconds?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorResources;
            /**
             * The number of attempts at getting topic metadata.
             */
            topicMetadataMaxAttempts?: number;
            /**
             * The namespace the Topic Operator should watch.
             */
            watchedNamespace?: string;
            /**
             * Timeout for the ZooKeeper session.
             */
            zookeeperSessionTimeoutSeconds?: number;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorTopicOperatorJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecEntityOperatorTopicOperatorJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecEntityOperatorTopicOperatorResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration of the User Operator.
         */
        export interface KafkaSpecEntityOperatorUserOperator {
            /**
             * The image to use for the User Operator.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorLivenessProbe;
            /**
             * Logging configuration.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorLogging;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorReadinessProbe;
            /**
             * Interval between periodic reconciliations.
             */
            reconciliationIntervalSeconds?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorResources;
            /**
             * The namespace the User Operator should watch.
             */
            watchedNamespace?: string;
            /**
             * Timeout for the ZooKeeper session.
             */
            zookeeperSessionTimeoutSeconds?: number;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecEntityOperatorUserOperatorJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecEntityOperatorUserOperatorJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecEntityOperatorUserOperatorJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecEntityOperatorUserOperatorLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration.
         */
        export interface KafkaSpecEntityOperatorUserOperatorLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecEntityOperatorUserOperatorReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecEntityOperatorUserOperatorResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration for JmxTrans. When the property is present a JmxTrans deployment is created for gathering JMX metrics from each Kafka broker. For more information see https://github.com/jmxtrans/jmxtrans[JmxTrans GitHub].
         */
        export interface KafkaSpecJmxTrans {
            /**
             * The image to use for the JmxTrans.
             */
            image?: string;
            /**
             * Queries to send to the Kafka brokers to define what data should be read from each broker. For more information on these properties see, xref:type-JmxTransQueryTemplate-reference[`JmxTransQueryTemplate` schema reference].
             */
            kafkaQueries: outputs.kafka.v1beta1.KafkaSpecJmxTransKafkaQueries[];
            /**
             * Sets the logging level of the JmxTrans deployment.For more information see, https://github.com/jmxtrans/jmxtrans-agent/wiki/Troubleshooting[JmxTrans Logging Level].
             */
            logLevel?: string;
            /**
             * Defines the output hosts that will be referenced later on. For more information on these properties see, xref:type-JmxTransOutputDefinitionTemplate-reference[`JmxTransOutputDefinitionTemplate` schema reference].
             */
            outputDefinitions: outputs.kafka.v1beta1.KafkaSpecJmxTransOutputDefinitions[];
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecJmxTransResources;
            /**
             * Template for JmxTrans resources.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplate;
        }

        export interface KafkaSpecJmxTransKafkaQueries {
            /**
             * Determine which attributes of the targeted MBean should be included.
             */
            attributes: string[];
            /**
             * List of the names of output definitions specified in the spec.kafka.jmxTrans.outputDefinitions that have defined where JMX metrics are pushed to, and in which data format.
             */
            outputs: string[];
            /**
             * If using wildcards instead of a specific MBean then the data is gathered from multiple MBeans. Otherwise if specifying an MBean then data is gathered from that specified MBean.
             */
            targetMBean: string;
        }

        export interface KafkaSpecJmxTransOutputDefinitions {
            /**
             * How many seconds the JmxTrans waits before pushing a new set of data out.
             */
            flushDelayInSeconds?: number;
            /**
             * The DNS/hostname of the remote host that the data is pushed to.
             */
            host?: string;
            /**
             * Template for setting the name of the output definition. This is used to identify where to send the results of queries should be sent.
             */
            name: string;
            /**
             * Template for setting the format of the data that will be pushed.For more information see https://github.com/jmxtrans/jmxtrans/wiki/OutputWriters[JmxTrans OutputWriters].
             */
            outputType: string;
            /**
             * The port of the remote host that the data is pushed to.
             */
            port?: number;
            /**
             * Template for filtering data to be included in response to a wildcard query. For more information see https://github.com/jmxtrans/jmxtrans/wiki/Queries[JmxTrans queries].
             */
            typeNames?: string[];
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecJmxTransResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Template for JmxTrans resources.
         */
        export interface KafkaSpecJmxTransTemplate {
            /**
             * Template for JmxTrans container.
             */
            container?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainer;
            /**
             * Template for JmxTrans `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateDeployment;
            /**
             * Template for JmxTrans `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePod;
        }

        /**
         * Template for JmxTrans container.
         */
        export interface KafkaSpecJmxTransTemplateContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContext;
        }

        export interface KafkaSpecJmxTransTemplateContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecJmxTransTemplateContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecJmxTransTemplateContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecJmxTransTemplateContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecJmxTransTemplateContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for JmxTrans `Deployment`.
         */
        export interface KafkaSpecJmxTransTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecJmxTransTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for JmxTrans `Pods`.
         */
        export interface KafkaSpecJmxTransTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecJmxTransTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecJmxTransTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecJmxTransTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecJmxTransTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecJmxTransTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecJmxTransTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecJmxTransTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecJmxTransTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Configuration of the Kafka cluster.
         */
        export interface KafkaSpecKafka {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinity;
            /**
             * Authorization configuration for Kafka brokers.
             */
            authorization?: outputs.kafka.v1beta1.KafkaSpecKafkaAuthorization;
            /**
             * The image of the init container used for initializing the `broker.rack`.
             */
            brokerRackInitImage?: string;
            /**
             * Kafka broker config properties with the following prefixes cannot be set: listeners, advertised., broker., listener., host.name, port, inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, zookeeper.connect, zookeeper.set.acl, zookeeper.ssl, zookeeper.clientCnxnSocket, authorizer., super.user, cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers (with the exception of: zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols,cruise.control.metrics.topic.num.partitions, cruise.control.metrics.topic.replication.factor, cruise.control.metrics.topic.retention.ms,cruise.control.metrics.topic.auto.create.retries, cruise.control.metrics.topic.auto.create.timeout.ms).
             */
            config?: {[key: string]: any};
            /**
             * The docker image for the pods. The default value depends on the configured `Kafka.spec.kafka.version`.
             */
            image?: string;
            /**
             * JMX Options for Kafka brokers.
             */
            jmxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaJmxOptions;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaJvmOptions;
            listeners: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0[] | outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaLivenessProbe;
            /**
             * Logging configuration for Kafka.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecKafkaLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Configuration of the `broker.rack` broker config.
             */
            rack?: outputs.kafka.v1beta1.KafkaSpecKafkaRack;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaReadinessProbe;
            /**
             * The number of pods in the cluster.
             */
            replicas: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecKafkaResources;
            /**
             * Storage configuration (disk). Cannot be updated.
             */
            storage: outputs.kafka.v1beta1.KafkaSpecKafkaStorage;
            /**
             * Template for Kafka cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplate;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecar;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecKafkaTolerations[];
            /**
             * The kafka broker version. Defaults to {DefaultKafkaVersion}. Consult the user documentation to understand the process required to upgrade or downgrade the version.
             */
            version?: string;
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecKafkaAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinity;
        }

        export interface KafkaSpecKafkaAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Authorization configuration for Kafka brokers.
         */
        export interface KafkaSpecKafkaAuthorization {
            /**
             * Defines whether a Kafka client should be allowed or denied by default when the authorizer fails to query the Open Policy Agent, for example, when it is temporarily unavailable). Defaults to `false` - all actions will be denied.
             */
            allowOnError?: boolean;
            /**
             * OAuth Client ID which the Kafka client can use to authenticate against the OAuth server and use the token endpoint URI.
             */
            clientId?: string;
            /**
             * Whether authorization decision should be delegated to the 'Simple' authorizer if DENIED by Keycloak Authorization Services policies. Default value is `false`.
             */
            delegateToKafkaAcls?: boolean;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * The expiration of the records kept in the local cache to avoid querying the Open Policy Agent for every request. Defines how often the cached authorization decisions are reloaded from the Open Policy Agent server. In milliseconds. Defaults to `3600000`.
             */
            expireAfterMs?: number;
            /**
             * The time between two consecutive grants refresh runs in seconds. The default value is 60.
             */
            grantsRefreshPeriodSeconds?: number;
            /**
             * The number of threads to use to refresh grants for active sessions. The more threads, the more parallelism, so the sooner the job completes. However, using more threads places a heavier load on the authorization server. The default value is 5.
             */
            grantsRefreshPoolSize?: number;
            /**
             * Initial capacity of the local cache used by the authorizer to avoid querying the Open Policy Agent for every request Defaults to `5000`.
             */
            initialCacheCapacity?: number;
            /**
             * Maximum capacity of the local cache used by the authorizer to avoid querying the Open Policy Agent for every request. Defaults to `50000`.
             */
            maximumCacheSize?: number;
            /**
             * List of super users. Should contain list of user principals which should get unlimited access rights.
             */
            superUsers?: string[];
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaAuthorizationTlsTrustedCertificates[];
            /**
             * Authorization server token endpoint URI.
             */
            tokenEndpointUri?: string;
            /**
             * Authorization type. Currently, the supported types are `simple`, `keycloak`, and `opa`. `simple` authorization type uses Kafka's `kafka.security.authorizer.AclAuthorizer` class for authorization. `keycloak` authorization type uses Keycloak Authorization Services for authorization. `opa` authorization type uses Open Policy Agent based authorization.
             */
            type: string;
            /**
             * The URL used to connect to the Open Policy Agent server. The URL has to include the policy which will be queried by the authorizer. This option is required.
             */
            url?: string;
        }

        export interface KafkaSpecKafkaAuthorizationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Configuration of the Kafka Exporter. Kafka Exporter can provide additional metrics, for example lag of consumer group at topic/partition.
         */
        export interface KafkaSpecKafkaExporter {
            /**
             * Enable Sarama logging, a Go client library used by the Kafka Exporter.
             */
            enableSaramaLogging?: boolean;
            /**
             * Regular expression to specify which consumer groups to collect. Default value is `.*`.
             */
            groupRegex?: string;
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * Pod liveness check.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterLivenessProbe;
            /**
             * Only log messages with the given severity or above. Valid levels: [`debug`, `info`, `warn`, `error`, `fatal`]. Default log level is `info`.
             */
            logging?: string;
            /**
             * Pod readiness check.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterResources;
            /**
             * Customization of deployment templates and pods.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplate;
            /**
             * Regular expression to specify which topics to collect. Default value is `.*`.
             */
            topicRegex?: string;
        }

        /**
         * Pod liveness check.
         */
        export interface KafkaSpecKafkaExporterLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness check.
         */
        export interface KafkaSpecKafkaExporterReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecKafkaExporterResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Customization of deployment templates and pods.
         */
        export interface KafkaSpecKafkaExporterTemplate {
            /**
             * Template for the Kafka Exporter container.
             */
            container?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainer;
            /**
             * Template for Kafka Exporter `Deployment`.
             */
            deployment?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateDeployment;
            /**
             * Template for Kafka Exporter `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePod;
            /**
             * Template for Kafka Exporter `Service`.
             */
            service?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateService;
        }

        /**
         * Template for the Kafka Exporter container.
         */
        export interface KafkaSpecKafkaExporterTemplateContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContext;
        }

        export interface KafkaSpecKafkaExporterTemplateContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaExporterTemplateContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka Exporter `Deployment`.
         */
        export interface KafkaSpecKafkaExporterTemplateDeployment {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateDeploymentMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaExporterTemplateDeploymentMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka Exporter `Pods`.
         */
        export interface KafkaSpecKafkaExporterTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecKafkaExporterTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaExporterTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaExporterTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaExporterTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecKafkaExporterTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaExporterTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecKafkaExporterTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for Kafka Exporter `Service`.
         */
        export interface KafkaSpecKafkaExporterTemplateService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaExporterTemplateServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaExporterTemplateServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * JMX Options for Kafka brokers.
         */
        export interface KafkaSpecKafkaJmxOptions {
            /**
             * Authentication configuration for connecting to the Kafka JMX port.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaJmxOptionsAuthentication;
        }

        /**
         * Authentication configuration for connecting to the Kafka JMX port.
         */
        export interface KafkaSpecKafkaJmxOptionsAuthentication {
            /**
             * Authentication type. Currently the only supported types are `password`.`password` type creates a username and protected port with no TLS.
             */
            type: string;
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecKafkaJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecKafkaJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecKafkaJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        export interface KafkaSpecKafkaListenersOneOf0 {
            /**
             * Authentication configuration for this listener.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0Authentication;
            /**
             * Additional listener configuration.
             */
            configuration?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0Configuration;
            /**
             * Name of the listener. The name will be used to identify the listener and the related Kubernetes objects. The name has to be unique within given a Kafka cluster. The name can consist of lowercase characters and numbers and be up to 11 characters long.
             */
            name: string;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeers[];
            /**
             * Port number used by the listener inside Kafka. The port number has to be unique within a given Kafka cluster. Allowed port numbers are 9092 and higher with the exception of ports 9404 and 9999, which are already used for Prometheus and JMX. Depending on the listener type, the port number might not be the same as the port number that connects Kafka clients.
             */
            port: number;
            /**
             * Enables TLS encryption on the listener. This is a required property.
             */
            tls: boolean;
            /**
             * Type of the listener. Currently the supported types are `internal`, `route`, `loadbalancer`, `nodeport` and `ingress`. 
             *
             * * `internal` type exposes Kafka internally only within the Kubernetes cluster.
             * * `route` type uses OpenShift Routes to expose Kafka.
             * * `loadbalancer` type uses LoadBalancer type services to expose Kafka.
             * * `nodeport` type uses NodePort type services to expose Kafka.
             * * `ingress` type uses Kubernetes Nginx Ingress to expose Kafka.
             * .
             */
            type: string;
        }

        /**
         * Authentication configuration for this listener.
         */
        export interface KafkaSpecKafkaListenersOneOf0Authentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0AuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0AuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf0AuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf0AuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Additional listener configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf0Configuration {
            /**
             * Bootstrap configuration.
             */
            bootstrap?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0ConfigurationBootstrap;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair which will be used for this listener. The certificate can optionally contain the whole chain. This field can be used only with listeners with enabled TLS encryption.
             */
            brokerCertChainAndKey?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0ConfigurationBrokerCertChainAndKey;
            /**
             * Per-broker configurations.
             */
            brokers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0ConfigurationBrokers[];
            /**
             * Configures the `Ingress` class that defines which `Ingress` controller will be used. If not set, the `Ingress` class is set to `nginx`. This field can be used only with `ingress` type listener.
             */
            class?: string;
            /**
             * Specifies whether the service routes external traffic to node-local or cluster-wide endpoints. `Cluster` may cause a second hop to another node and obscures the client source IP. `Local` avoids a second hop for LoadBalancer and Nodeport type services and preserves the client source IP (when supported by the infrastructure). If unspecified, Kubernetes will use `Cluster` as the default.This field can be used only with `loadbalancer` or `nodeport` type listener.
             */
            externalTrafficPolicy?: string;
            /**
             * A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. This field can be used only with `loadbalancer` type listener.
             */
            loadBalancerSourceRanges?: string[];
            /**
             * Defines which address type should be used as the node address. Available types are: `ExternalDNS`, `ExternalIP`, `InternalDNS`, `InternalIP` and `Hostname`. By default, the addresses will be used in the following order (the first one found will be used):
             * * `ExternalDNS`
             * * `ExternalIP`
             * * `InternalDNS`
             * * `InternalIP`
             * * `Hostname`
             *
             * This field can be used to select the address type which will be used as the preferred type and checked first. In case no address will be found for this address type, the other types will be used in the default order.This field can be used only with `nodeport` type listener..
             */
            preferredNodePortAddressType?: string;
            /**
             * Configures whether the Kubernetes service DNS domain should be used or not. If set to `true`, the generated addresses with contain the service DNS domain suffix (by default `.cluster.local`, can be configured using environment variable `KUBERNETES_SERVICE_DNS_DOMAIN`). Defaults to `false`.This field can be used only with `internal` type listener.
             */
            useServiceDnsDomain?: boolean;
        }

        /**
         * Bootstrap configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf0ConfigurationBootstrap {
            /**
             * Additional alternative names for the bootstrap service. The alternative names will be added to the list of subject alternative names of the TLS certificates.
             */
            alternativeNames?: string[];
            /**
             * Annotations that will be added to the `Ingress` or `Service` resource. You can use this field to configure DNS providers such as External DNS. This field can be used only with `loadbalancer`, `nodeport`, or `ingress` type listeners.
             */
            annotations?: {[key: string]: any};
            /**
             * The bootstrap host. This field will be used in the Ingress resource or in the Route resource to specify the desired hostname. This field can be used only with `route` (optional) or `ingress` (required) type listeners.
             */
            host?: string;
            /**
             * The loadbalancer is requested with the IP address specified in this field. This feature depends on whether the underlying cloud provider supports specifying the `loadBalancerIP` when a load balancer is created. This field is ignored if the cloud provider does not support the feature.This field can be used only with `loadbalancer` type listener.
             */
            loadBalancerIP?: string;
            /**
             * Node port for the bootstrap service. This field can be used only with `nodeport` type listener.
             */
            nodePort?: number;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair which will be used for this listener. The certificate can optionally contain the whole chain. This field can be used only with listeners with enabled TLS encryption.
         */
        export interface KafkaSpecKafkaListenersOneOf0ConfigurationBrokerCertChainAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf0ConfigurationBrokers {
            /**
             * The host name which will be used in the brokers' `advertised.brokers`.
             */
            advertisedHost?: string;
            /**
             * The port number which will be used in the brokers' `advertised.brokers`.
             */
            advertisedPort?: number;
            /**
             * Annotations that will be added to the `Ingress` or `Service` resource. You can use this field to configure DNS providers such as External DNS. This field can be used only with `loadbalancer`, `nodeport`, or `ingress` type listeners.
             */
            annotations?: {[key: string]: any};
            /**
             * ID of the kafka broker (broker identifier). Broker IDs start from 0 and correspond to the number of broker replicas.
             */
            broker: number;
            /**
             * The broker host. This field will be used in the Ingress resource or in the Route resource to specify the desired hostname. This field can be used only with `route` (optional) or `ingress` (required) type listeners.
             */
            host?: string;
            /**
             * The loadbalancer is requested with the IP address specified in this field. This feature depends on whether the underlying cloud provider supports specifying the `loadBalancerIP` when a load balancer is created. This field is ignored if the cloud provider does not support the feature.This field can be used only with `loadbalancer` type listener.
             */
            loadBalancerIP?: string;
            /**
             * Node port for the per-broker service. This field can be used only with `nodeport` type listener.
             */
            nodePort?: number;
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf0NetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1 {
            /**
             * Configures external listener on port 9094.
             */
            external?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1External;
            /**
             * Configures plain listener on port 9092.
             */
            plain?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1Plain;
            /**
             * Configures TLS listener on port 9093.
             */
            tls?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1Tls;
        }

        /**
         * Configures external listener on port 9094.
         */
        export interface KafkaSpecKafkaListenersOneOf1External {
            /**
             * Authentication configuration for Kafka brokers.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalAuthentication;
            /**
             * Configures the `Ingress` class that defines which `Ingress` controller will be used. If not set, the `Ingress` class is set to `nginx`.
             */
            class?: string;
            /**
             * External listener configuration.
             */
            configuration?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfiguration;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeers[];
            /**
             * Overrides for external bootstrap and broker services and externally advertised addresses.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalOverrides;
            /**
             * Enables TLS encryption on the listener. By default set to `true` for enabled TLS encryption.
             */
            tls?: boolean;
            /**
             * Type of the external listener. Currently the supported types are `route`, `loadbalancer`, and `nodeport`. 
             *
             * * `route` type uses OpenShift Routes to expose Kafka.* `loadbalancer` type uses LoadBalancer type services to expose Kafka.* `nodeport` type uses NodePort type services to expose Kafka..
             */
            type: string;
        }

        /**
         * Authentication configuration for Kafka brokers.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalAuthentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalAuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * External listener configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalConfiguration {
            /**
             * External bootstrap ingress configuration.
             */
            bootstrap?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfigurationBootstrap;
            /**
             * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
             */
            brokerCertChainAndKey?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokerCertChainAndKey;
            /**
             * External broker ingress configuration.
             */
            brokers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokers[];
        }

        /**
         * External bootstrap ingress configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalConfigurationBootstrap {
            /**
             * Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.
             */
            address?: string;
            /**
             * Annotations that will be added to the `Ingress` resource. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Host for the bootstrap route. This field will be used in the Ingress resource.
             */
            host: string;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokerCertChainAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalConfigurationBrokers {
            /**
             * The host name which will be used in the brokers' `advertised.brokers`.
             */
            advertisedHost?: string;
            /**
             * The port number which will be used in the brokers' `advertised.brokers`.
             */
            advertisedPort?: number;
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * Annotations that will be added to the `Ingress` resources for individual brokers. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Host for the broker ingress. This field will be used in the Ingress resource.
             */
            host: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalNetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Overrides for external bootstrap and broker services and externally advertised addresses.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalOverrides {
            /**
             * External bootstrap service configuration.
             */
            bootstrap?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalOverridesBootstrap;
            /**
             * External broker services configuration.
             */
            brokers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1ExternalOverridesBrokers[];
        }

        /**
         * External bootstrap service configuration.
         */
        export interface KafkaSpecKafkaListenersOneOf1ExternalOverridesBootstrap {
            /**
             * Additional address name for the bootstrap service. The address will be added to the list of subject alternative names of the TLS certificates.
             */
            address?: string;
            /**
             * Annotations that will be added to the `Service` resource. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Node port for the bootstrap service.
             */
            nodePort?: number;
        }

        export interface KafkaSpecKafkaListenersOneOf1ExternalOverridesBrokers {
            /**
             * The host name which will be used in the brokers' `advertised.brokers`.
             */
            advertisedHost?: string;
            /**
             * The port number which will be used in the brokers' `advertised.brokers`.
             */
            advertisedPort?: number;
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * Annotations that will be added to the `Service` resources for individual brokers. You can use this field to configure DNS providers such as External DNS.
             */
            dnsAnnotations?: {[key: string]: any};
            /**
             * Node port for the broker service.
             */
            nodePort?: number;
        }

        /**
         * Configures plain listener on port 9092.
         */
        export interface KafkaSpecKafkaListenersOneOf1Plain {
            /**
             * Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with `type: tls`.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainAuthentication;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeers[];
        }

        /**
         * Authentication configuration for this listener. Since this listener does not use TLS transport you cannot configure an authentication with `type: tls`.
         */
        export interface KafkaSpecKafkaListenersOneOf1PlainAuthentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainAuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf1PlainAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1PlainNetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Configures TLS listener on port 9093.
         */
        export interface KafkaSpecKafkaListenersOneOf1Tls {
            /**
             * Authentication configuration for this listener.
             */
            authentication?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsAuthentication;
            /**
             * Configuration of TLS listener.
             */
            configuration?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsConfiguration;
            /**
             * List of peers which should be able to connect to this listener. Peers in this list are combined using a logical OR operation. If this field is empty or missing, all connections will be allowed for this listener. If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.
             */
            networkPolicyPeers?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeers[];
        }

        /**
         * Authentication configuration for this listener.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsAuthentication {
            /**
             * Configure whether the access token is treated as JWT. This must be set to `false` if the authorization server returns opaque tokens. Defaults to `true`.
             */
            accessTokenIsJwt?: boolean;
            /**
             * Configure whether the access token type check is performed or not. This should be set to `false` if the authorization server does not include 'typ' claim in JWT token. Defaults to `true`.
             */
            checkAccessTokenType?: boolean;
            /**
             * Enable or disable issuer checking. By default issuer is checked using the value configured by `validIssuerUri`. Default value is `true`.
             */
            checkIssuer?: boolean;
            /**
             * OAuth Client ID which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientId?: string;
            /**
             * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
             */
            clientSecret?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsAuthenticationClientSecret;
            /**
             * Enable or disable TLS hostname verification. Default value is `false`.
             */
            disableTlsHostnameVerification?: boolean;
            /**
             * Enable or disable ECDSA support by installing BouncyCastle crypto provider. Default value is `false`.
             */
            enableECDSA?: boolean;
            /**
             * The fallback username claim to be used for the user id if the claim specified by `userNameClaim` is not present. This is useful when `client_credentials` authentication only results in the client id being provided in another claim. It only takes effect if `userNameClaim` is set.
             */
            fallbackUserNameClaim?: string;
            /**
             * The prefix to use with the value of `fallbackUserNameClaim` to construct the user id. This only takes effect if `fallbackUserNameClaim` is true, and the value is present for the claim. Mapping usernames and client ids into the same user id space is useful in preventing name collisions.
             */
            fallbackUserNamePrefix?: string;
            /**
             * URI of the token introspection endpoint which can be used to validate opaque non-JWT tokens.
             */
            introspectionEndpointUri?: string;
            /**
             * URI of the JWKS certificate endpoint, which can be used for local JWT validation.
             */
            jwksEndpointUri?: string;
            /**
             * Configures how often are the JWKS certificates considered valid. The expiry interval has to be at least 60 seconds longer then the refresh interval specified in `jwksRefreshSeconds`. Defaults to 360 seconds.
             */
            jwksExpirySeconds?: number;
            /**
             * The minimum pause between two consecutive refreshes. When an unknown signing key is encountered the refresh is scheduled immediately, but will always wait for this minimum pause. Defaults to 1 second.
             */
            jwksMinRefreshPauseSeconds?: number;
            /**
             * Configures how often are the JWKS certificates refreshed. The refresh interval has to be at least 60 seconds shorter then the expiry interval specified in `jwksExpirySeconds`. Defaults to 300 seconds.
             */
            jwksRefreshSeconds?: number;
            /**
             * Maximum number of seconds the authenticated session remains valid without re-authentication. This enables Apache Kafka re-authentication feature, and causes sessions to expire when the access token expires. If the access token expires before max time or if max time is reached, the client has to re-authenticate, otherwise the server will drop the connection. Not set by default - the authenticated session does not expire when the access token expires.
             */
            maxSecondsWithoutReauthentication?: number;
            /**
             * Trusted certificates for TLS connection to the OAuth server.
             */
            tlsTrustedCertificates?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsAuthenticationTlsTrustedCertificates[];
            /**
             * Authentication type. `oauth` type uses SASL OAUTHBEARER Authentication. `scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. `tls` type uses TLS Client Authentication. `tls` type is supported only on TLS listeners.
             */
            type: string;
            /**
             * URI of the User Info Endpoint to use as a fallback to obtaining the user id when the Introspection Endpoint does not return information that can be used for the user id. 
             */
            userInfoEndpointUri?: string;
            /**
             * Name of the claim from the JWT authentication token, Introspection Endpoint response or User Info Endpoint response which will be used to extract the user id. Defaults to `sub`.
             */
            userNameClaim?: string;
            /**
             * URI of the token issuer used for authentication.
             */
            validIssuerUri?: string;
            /**
             * Valid value for the `token_type` attribute returned by the Introspection Endpoint. No default value, and not checked by default.
             */
            validTokenType?: string;
        }

        /**
         * Link to Kubernetes Secret containing the OAuth client secret which the Kafka broker can use to authenticate against the authorization server and use the introspect endpoint URI.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsAuthenticationClientSecret {
            /**
             * The key under which the secret value is stored in the Kubernetes Secret.
             */
            key: string;
            /**
             * The name of the Kubernetes Secret containing the secret value.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsAuthenticationTlsTrustedCertificates {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        /**
         * Configuration of TLS listener.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsConfiguration {
            /**
             * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
             */
            brokerCertChainAndKey?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsConfigurationBrokerCertChainAndKey;
        }

        /**
         * Reference to the `Secret` which holds the certificate and private key pair. The certificate can optionally contain the whole chain.
         */
        export interface KafkaSpecKafkaListenersOneOf1TlsConfigurationBrokerCertChainAndKey {
            /**
             * The name of the file certificate in the Secret.
             */
            certificate: string;
            /**
             * The name of the private key in the Secret.
             */
            key: string;
            /**
             * The name of the Secret containing the certificate.
             */
            secretName: string;
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeers {
            ipBlock?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersIpBlock;
            namespaceSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelector;
            podSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelector;
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersIpBlock {
            cidr?: string;
            except?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersNamespaceSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaListenersOneOf1TlsNetworkPolicyPeersPodSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecKafkaLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for Kafka.
         */
        export interface KafkaSpecKafkaLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Configuration of the `broker.rack` broker config.
         */
        export interface KafkaSpecKafkaRack {
            /**
             * A key that matches labels assigned to the Kubernetes cluster nodes. The value of the label is used to set the broker's `broker.rack` config.
             */
            topologyKey: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecKafkaReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecKafkaResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Storage configuration (disk). Cannot be updated.
         */
        export interface KafkaSpecKafkaStorage {
            /**
             * The storage class to use for dynamic volume allocation.
             */
            class?: string;
            /**
             * Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.
             */
            deleteClaim?: boolean;
            /**
             * Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.
             */
            id?: number;
            /**
             * Overrides for individual brokers. The `overrides` field allows to specify a different configuration for different brokers.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecKafkaStorageOverrides[];
            /**
             * Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.
             */
            selector?: {[key: string]: any};
            /**
             * When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.
             */
            size?: string;
            /**
             * When type=ephemeral, defines the total amount of local storage required for this EmptyDir volume (for example 1Gi).
             */
            sizeLimit?: string;
            /**
             * Storage type, must be either 'ephemeral', 'persistent-claim', or 'jbod'.
             */
            type: string;
            /**
             * List of volumes as Storage objects representing the JBOD disks array.
             */
            volumes?: outputs.kafka.v1beta1.KafkaSpecKafkaStorageVolumes[];
        }

        export interface KafkaSpecKafkaStorageOverrides {
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * The storage class to use for dynamic volume allocation for this broker.
             */
            class?: string;
        }

        export interface KafkaSpecKafkaStorageVolumes {
            /**
             * The storage class to use for dynamic volume allocation.
             */
            class?: string;
            /**
             * Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.
             */
            deleteClaim?: boolean;
            /**
             * Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.
             */
            id?: number;
            /**
             * Overrides for individual brokers. The `overrides` field allows to specify a different configuration for different brokers.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecKafkaStorageVolumesOverrides[];
            /**
             * Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.
             */
            selector?: {[key: string]: any};
            /**
             * When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.
             */
            size?: string;
            /**
             * When type=ephemeral, defines the total amount of local storage required for this EmptyDir volume (for example 1Gi).
             */
            sizeLimit?: string;
            /**
             * Storage type, must be either 'ephemeral' or 'persistent-claim'.
             */
            type: string;
        }

        export interface KafkaSpecKafkaStorageVolumesOverrides {
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * The storage class to use for dynamic volume allocation for this broker.
             */
            class?: string;
        }

        /**
         * Template for Kafka cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
         */
        export interface KafkaSpecKafkaTemplate {
            /**
             * Template for Kafka bootstrap `Service`.
             */
            bootstrapService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBootstrapService;
            /**
             * Template for Kafka broker `Service`.
             */
            brokersService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBrokersService;
            /**
             * Template for Kafka external bootstrap `Ingress`.
             */
            externalBootstrapIngress?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapIngress;
            /**
             * Template for Kafka external bootstrap `Route`.
             */
            externalBootstrapRoute?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapRoute;
            /**
             * Template for Kafka external bootstrap `Service`.
             */
            externalBootstrapService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapService;
            /**
             * Template for the Kafka init container.
             */
            initContainer?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainer;
            /**
             * Template for the Kafka broker container.
             */
            kafkaContainer?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainer;
            /**
             * Template for Kafka per-pod `Ingress` used for access from outside of Kubernetes.
             */
            perPodIngress?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodIngress;
            /**
             * Template for Kafka per-pod `Routes` used for access from outside of OpenShift.
             */
            perPodRoute?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodRoute;
            /**
             * Template for Kafka per-pod `Services` used for access from outside of Kubernetes.
             */
            perPodService?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodService;
            /**
             * Template for all Kafka `PersistentVolumeClaims`.
             */
            persistentVolumeClaim?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePersistentVolumeClaim;
            /**
             * Template for Kafka `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePod;
            /**
             * Template for Kafka `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodDisruptionBudget;
            /**
             * Template for Kafka `StatefulSet`.
             */
            statefulset?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateStatefulset;
            /**
             * Template for the Kafka broker TLS sidecar container.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainer;
        }

        /**
         * Template for Kafka bootstrap `Service`.
         */
        export interface KafkaSpecKafkaTemplateBootstrapService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBootstrapServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateBootstrapServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka broker `Service`.
         */
        export interface KafkaSpecKafkaTemplateBrokersService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateBrokersServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateBrokersServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka external bootstrap `Ingress`.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapIngress {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapIngressMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapIngressMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka external bootstrap `Route`.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapRoute {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapRouteMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapRouteMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka external bootstrap `Service`.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapService {
            /**
             * Specifies whether the service routes external traffic to node-local or cluster-wide endpoints. `Cluster` may cause a second hop to another node and obscures the client source IP. `Local` avoids a second hop for LoadBalancer and Nodeport type services and preserves the client source IP (when supported by the infrastructure). If unspecified, Kubernetes will use `Cluster` as the default.
             */
            externalTrafficPolicy?: string;
            /**
             * A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. 
             */
            loadBalancerSourceRanges?: string[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateExternalBootstrapServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateExternalBootstrapServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka init container.
         */
        export interface KafkaSpecKafkaTemplateInitContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContext;
        }

        export interface KafkaSpecKafkaTemplateInitContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaTemplateInitContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateInitContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplateInitContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaTemplateInitContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplateInitContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the Kafka broker container.
         */
        export interface KafkaSpecKafkaTemplateKafkaContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContext;
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateKafkaContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplateKafkaContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for Kafka per-pod `Ingress` used for access from outside of Kubernetes.
         */
        export interface KafkaSpecKafkaTemplatePerPodIngress {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodIngressMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePerPodIngressMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka per-pod `Routes` used for access from outside of OpenShift.
         */
        export interface KafkaSpecKafkaTemplatePerPodRoute {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodRouteMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePerPodRouteMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka per-pod `Services` used for access from outside of Kubernetes.
         */
        export interface KafkaSpecKafkaTemplatePerPodService {
            /**
             * Specifies whether the service routes external traffic to node-local or cluster-wide endpoints. `Cluster` may cause a second hop to another node and obscures the client source IP. `Local` avoids a second hop for LoadBalancer and Nodeport type services and preserves the client source IP (when supported by the infrastructure). If unspecified, Kubernetes will use `Cluster` as the default.
             */
            externalTrafficPolicy?: string;
            /**
             * A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. 
             */
            loadBalancerSourceRanges?: string[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePerPodServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePerPodServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for all Kafka `PersistentVolumeClaims`.
         */
        export interface KafkaSpecKafkaTemplatePersistentVolumeClaim {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePersistentVolumeClaimMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePersistentVolumeClaimMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for Kafka `Pods`.
         */
        export interface KafkaSpecKafkaTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecKafkaTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for Kafka `PodDisruptionBudget`.
         */
        export interface KafkaSpecKafkaTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaSpecKafkaTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecKafkaTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecKafkaTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecKafkaTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecKafkaTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for Kafka `StatefulSet`.
         */
        export interface KafkaSpecKafkaTemplateStatefulset {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateStatefulsetMetadata;
            /**
             * PodManagementPolicy which will be used for this StatefulSet. Valid values are `Parallel` and `OrderedReady`. Defaults to `Parallel`.
             */
            podManagementPolicy?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecKafkaTemplateStatefulsetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Kafka broker TLS sidecar container.
         */
        export interface KafkaSpecKafkaTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecKafkaTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecKafkaTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecKafkaTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecKafkaTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecKafkaTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecKafkaTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        export interface KafkaSpecKafkaTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Configuration of the Topic Operator.
         */
        export interface KafkaSpecTopicOperator {
            /**
             * Pod affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinity;
            /**
             * The image to use for the Topic Operator.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorLivenessProbe;
            /**
             * Logging configuration.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorLogging;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorReadinessProbe;
            /**
             * Interval between periodic reconciliations.
             */
            reconciliationIntervalSeconds?: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorResources;
            /**
             * TLS sidecar configuration.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecar;
            /**
             * The number of attempts at getting topic metadata.
             */
            topicMetadataMaxAttempts?: number;
            /**
             * The namespace the Topic Operator should watch.
             */
            watchedNamespace?: string;
            /**
             * Timeout for the ZooKeeper session.
             */
            zookeeperSessionTimeoutSeconds?: number;
        }

        /**
         * Pod affinity rules.
         */
        export interface KafkaSpecTopicOperatorAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinity;
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecTopicOperatorAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecTopicOperatorJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecTopicOperatorJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecTopicOperatorLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration.
         */
        export interface KafkaSpecTopicOperatorLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecTopicOperatorReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecTopicOperatorResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * TLS sidecar configuration.
         */
        export interface KafkaSpecTopicOperatorTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecTopicOperatorTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecTopicOperatorTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecTopicOperatorTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecTopicOperatorTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Configuration of the ZooKeeper cluster.
         */
        export interface KafkaSpecZookeeper {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinity;
            /**
             * The ZooKeeper broker config. Properties with the following prefixes cannot be set: server., dataDir, dataLogDir, clientPort, authProvider, quorum.auth, requireClientAuthScheme, snapshot.trust.empty, standaloneEnabled, reconfigEnabled, 4lw.commands.whitelist, secureClientPort, ssl., serverCnxnFactory, sslQuorum (with the exception of: ssl.protocol, ssl.quorum.protocol, ssl.enabledProtocols, ssl.quorum.enabledProtocols, ssl.ciphersuites, ssl.quorum.ciphersuites, ssl.hostnameVerification, ssl.quorum.hostnameVerification).
             */
            config?: {[key: string]: any};
            /**
             * The docker image for the pods.
             */
            image?: string;
            /**
             * JVM Options for pods.
             */
            jvmOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperJvmOptions;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperLivenessProbe;
            /**
             * Logging configuration for ZooKeeper.
             */
            logging?: outputs.kafka.v1beta1.KafkaSpecZookeeperLogging;
            /**
             * The Prometheus JMX Exporter configuration. See https://github.com/prometheus/jmx_exporter for details of the structure of this configuration.
             */
            metrics?: {[key: string]: any};
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperReadinessProbe;
            /**
             * The number of pods in the cluster.
             */
            replicas: number;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecZookeeperResources;
            /**
             * Storage configuration (disk). Cannot be updated.
             */
            storage: outputs.kafka.v1beta1.KafkaSpecZookeeperStorage;
            /**
             * Template for ZooKeeper cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
             */
            template?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplate;
            /**
             * TLS sidecar configuration. The TLS sidecar is not used anymore and this option will be ignored.
             */
            tlsSidecar?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecar;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecZookeeperTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecZookeeperAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinity;
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * JVM Options for pods.
         */
        export interface KafkaSpecZookeeperJvmOptions {
            /**
             * A map of -XX options to the JVM.
             */
            -XX?: {[key: string]: any};
            /**
             * -Xms option to to the JVM.
             */
            -Xms?: string;
            /**
             * -Xmx option to to the JVM.
             */
            -Xmx?: string;
            /**
             * Specifies whether the Garbage Collection logging is enabled. The default is false.
             */
            gcLoggingEnabled?: boolean;
            /**
             * A map of additional system properties which will be passed using the `-D` option to the JVM.
             */
            javaSystemProperties?: outputs.kafka.v1beta1.KafkaSpecZookeeperJvmOptionsJavaSystemProperties[];
        }

        export interface KafkaSpecZookeeperJvmOptionsJavaSystemProperties {
            /**
             * The system property name.
             */
            name?: string;
            /**
             * The system property value.
             */
            value?: string;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecZookeeperLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Logging configuration for ZooKeeper.
         */
        export interface KafkaSpecZookeeperLogging {
            /**
             * A Map from logger name to logger level.
             */
            loggers?: {[key: string]: any};
            /**
             * The name of the `ConfigMap` from which to get the logging configuration.
             */
            name?: string;
            /**
             * Logging type, must be either 'inline' or 'external'.
             */
            type: string;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecZookeeperReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecZookeeperResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        /**
         * Storage configuration (disk). Cannot be updated.
         */
        export interface KafkaSpecZookeeperStorage {
            /**
             * The storage class to use for dynamic volume allocation.
             */
            class?: string;
            /**
             * Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.
             */
            deleteClaim?: boolean;
            /**
             * Storage identification number. It is mandatory only for storage volumes defined in a storage of type 'jbod'.
             */
            id?: number;
            /**
             * Overrides for individual brokers. The `overrides` field allows to specify a different configuration for different brokers.
             */
            overrides?: outputs.kafka.v1beta1.KafkaSpecZookeeperStorageOverrides[];
            /**
             * Specifies a specific persistent volume to use. It contains key:value pairs representing labels for selecting such a volume.
             */
            selector?: {[key: string]: any};
            /**
             * When type=persistent-claim, defines the size of the persistent volume claim (i.e 1Gi). Mandatory when type=persistent-claim.
             */
            size?: string;
            /**
             * When type=ephemeral, defines the total amount of local storage required for this EmptyDir volume (for example 1Gi).
             */
            sizeLimit?: string;
            /**
             * Storage type, must be either 'ephemeral' or 'persistent-claim'.
             */
            type: string;
        }

        export interface KafkaSpecZookeeperStorageOverrides {
            /**
             * Id of the kafka broker (broker identifier).
             */
            broker?: number;
            /**
             * The storage class to use for dynamic volume allocation for this broker.
             */
            class?: string;
        }

        /**
         * Template for ZooKeeper cluster resources. The template allows users to specify how are the `StatefulSet`, `Pods` and `Services` generated.
         */
        export interface KafkaSpecZookeeperTemplate {
            /**
             * Template for ZooKeeper client `Service`.
             */
            clientService?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateClientService;
            /**
             * Template for ZooKeeper nodes `Service`.
             */
            nodesService?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateNodesService;
            /**
             * Template for all ZooKeeper `PersistentVolumeClaims`.
             */
            persistentVolumeClaim?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePersistentVolumeClaim;
            /**
             * Template for ZooKeeper `Pods`.
             */
            pod?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePod;
            /**
             * Template for ZooKeeper `PodDisruptionBudget`.
             */
            podDisruptionBudget?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodDisruptionBudget;
            /**
             * Template for ZooKeeper `StatefulSet`.
             */
            statefulset?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateStatefulset;
            /**
             * Template for the Zookeeper server TLS sidecar container. The TLS sidecar is not used anymore and this option will be ignored.
             */
            tlsSidecarContainer?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainer;
            /**
             * Template for the ZooKeeper container.
             */
            zookeeperContainer?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainer;
        }

        /**
         * Template for ZooKeeper client `Service`.
         */
        export interface KafkaSpecZookeeperTemplateClientService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateClientServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplateClientServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for ZooKeeper nodes `Service`.
         */
        export interface KafkaSpecZookeeperTemplateNodesService {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateNodesServiceMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplateNodesServiceMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for all ZooKeeper `PersistentVolumeClaims`.
         */
        export interface KafkaSpecZookeeperTemplatePersistentVolumeClaim {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePersistentVolumeClaimMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplatePersistentVolumeClaimMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for ZooKeeper `Pods`.
         */
        export interface KafkaSpecZookeeperTemplatePod {
            /**
             * The pod's affinity rules.
             */
            affinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinity;
            /**
             * The pod's HostAliases. HostAliases is an optional list of hosts and IPs that will be injected into the pod's hosts file if specified.
             */
            hostAliases?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodHostAliases[];
            /**
             * List of references to secrets in the same namespace to use for pulling any of the images used by this Pod. When the `STRIMZI_IMAGE_PULL_SECRETS` environment variable in Cluster Operator and the `imagePullSecrets` option are specified, only the `imagePullSecrets` variable is used and the `STRIMZI_IMAGE_PULL_SECRETS` variable is ignored.
             */
            imagePullSecrets?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodImagePullSecrets[];
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodMetadata;
            /**
             * The name of the priority class used to assign priority to the pods. For more information about priority classes, see {K8sPriorityClass}.
             */
            priorityClassName?: string;
            /**
             * The name of the scheduler used to dispatch this `Pod`. If not specified, the default scheduler will be used.
             */
            schedulerName?: string;
            /**
             * Configures pod-level security attributes and common container settings.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContext;
            /**
             * The grace period is the duration in seconds after the processes running in the pod are sent a termination signal, and the time when the processes are forcibly halted with a kill signal. Set this value to longer than the expected cleanup time for your process. Value must be a non-negative integer. A zero value indicates delete immediately. You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. Defaults to 30 seconds.
             */
            terminationGracePeriodSeconds?: number;
            /**
             * The pod's tolerations.
             */
            tolerations?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodTolerations[];
        }

        /**
         * The pod's affinity rules.
         */
        export interface KafkaSpecZookeeperTemplatePodAffinity {
            nodeAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinity;
            podAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinity;
            podAntiAffinity?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinity;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            preference?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference;
            weight?: number;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreference {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityPreferredDuringSchedulingIgnoredDuringExecutionPreferenceMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            nodeSelectorTerms?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTerms {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions[];
            matchFields?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityNodeAffinityRequiredDuringSchedulingIgnoredDuringExecutionNodeSelectorTermsMatchFields {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinity {
            preferredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution[];
            requiredDuringSchedulingIgnoredDuringExecution?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecution {
            podAffinityTerm?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm;
            weight?: number;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTerm {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityPreferredDuringSchedulingIgnoredDuringExecutionPodAffinityTermLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecution {
            labelSelector?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector;
            namespaces?: string[];
            topologyKey?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelector {
            matchExpressions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions[];
            matchLabels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodAffinityPodAntiAffinityRequiredDuringSchedulingIgnoredDuringExecutionLabelSelectorMatchExpressions {
            key?: string;
            operator?: string;
            values?: string[];
        }

        /**
         * Template for ZooKeeper `PodDisruptionBudget`.
         */
        export interface KafkaSpecZookeeperTemplatePodDisruptionBudget {
            /**
             * Maximum number of unavailable pods to allow automatic Pod eviction. A Pod eviction is allowed when the `maxUnavailable` number of pods or fewer are unavailable after the eviction. Setting this value to 0 prevents all voluntary evictions, so the pods must be evicted manually. Defaults to 1.
             */
            maxUnavailable?: number;
            /**
             * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodDisruptionBudgetMetadata;
        }

        /**
         * Metadata to apply to the `PodDistruptionBugetTemplate` resource.
         */
        export interface KafkaSpecZookeeperTemplatePodDisruptionBudgetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTemplatePodHostAliases {
            hostnames?: string[];
            ip?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodImagePullSecrets {
            name?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplatePodMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Configures pod-level security attributes and common container settings.
         */
        export interface KafkaSpecZookeeperTemplatePodSecurityContext {
            fsGroup?: number;
            fsGroupChangePolicy?: string;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContextSeLinuxOptions;
            supplementalGroups?: number[];
            sysctls?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContextSysctls[];
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplatePodSecurityContextWindowsOptions;
        }

        export interface KafkaSpecZookeeperTemplatePodSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodSecurityContextSysctls {
            name?: string;
            value?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        export interface KafkaSpecZookeeperTemplatePodTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * Template for ZooKeeper `StatefulSet`.
         */
        export interface KafkaSpecZookeeperTemplateStatefulset {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateStatefulsetMetadata;
            /**
             * PodManagementPolicy which will be used for this StatefulSet. Valid values are `Parallel` and `OrderedReady`. Defaults to `Parallel`.
             */
            podManagementPolicy?: string;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaSpecZookeeperTemplateStatefulsetMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * Template for the Zookeeper server TLS sidecar container. The TLS sidecar is not used anymore and this option will be ignored.
         */
        export interface KafkaSpecZookeeperTemplateTlsSidecarContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContext;
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecZookeeperTemplateTlsSidecarContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * Template for the ZooKeeper container.
         */
        export interface KafkaSpecZookeeperTemplateZookeeperContainer {
            /**
             * Environment variables which should be applied to the container.
             */
            env?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerEnv[];
            /**
             * Security context for the container.
             */
            securityContext?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContext;
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerEnv {
            /**
             * The environment variable key.
             */
            name?: string;
            /**
             * The environment variable value.
             */
            value?: string;
        }

        /**
         * Security context for the container.
         */
        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContext {
            allowPrivilegeEscalation?: boolean;
            capabilities?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextCapabilities;
            privileged?: boolean;
            procMount?: string;
            readOnlyRootFilesystem?: boolean;
            runAsGroup?: number;
            runAsNonRoot?: boolean;
            runAsUser?: number;
            seLinuxOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextSeLinuxOptions;
            windowsOptions?: outputs.kafka.v1beta1.KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextWindowsOptions;
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextCapabilities {
            add?: string[];
            drop?: string[];
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextSeLinuxOptions {
            level?: string;
            role?: string;
            type?: string;
            user?: string;
        }

        export interface KafkaSpecZookeeperTemplateZookeeperContainerSecurityContextWindowsOptions {
            gmsaCredentialSpec?: string;
            gmsaCredentialSpecName?: string;
            runAsUserName?: string;
        }

        /**
         * TLS sidecar configuration. The TLS sidecar is not used anymore and this option will be ignored.
         */
        export interface KafkaSpecZookeeperTlsSidecar {
            /**
             * The docker image for the container.
             */
            image?: string;
            /**
             * Pod liveness checking.
             */
            livenessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecarLivenessProbe;
            /**
             * The log level for the TLS sidecar. Default value is `notice`.
             */
            logLevel?: string;
            /**
             * Pod readiness checking.
             */
            readinessProbe?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecarReadinessProbe;
            /**
             * CPU and memory resources to reserve.
             */
            resources?: outputs.kafka.v1beta1.KafkaSpecZookeeperTlsSidecarResources;
        }

        /**
         * Pod liveness checking.
         */
        export interface KafkaSpecZookeeperTlsSidecarLivenessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * Pod readiness checking.
         */
        export interface KafkaSpecZookeeperTlsSidecarReadinessProbe {
            /**
             * Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1.
             */
            failureThreshold?: number;
            /**
             * The initial delay before first the health is first checked.
             */
            initialDelaySeconds?: number;
            /**
             * How often (in seconds) to perform the probe. Default to 10 seconds. Minimum value is 1.
             */
            periodSeconds?: number;
            /**
             * Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness. Minimum value is 1.
             */
            successThreshold?: number;
            /**
             * The timeout for each attempted health check.
             */
            timeoutSeconds?: number;
        }

        /**
         * CPU and memory resources to reserve.
         */
        export interface KafkaSpecZookeeperTlsSidecarResources {
            limits?: {[key: string]: any};
            requests?: {[key: string]: any};
        }

        export interface KafkaSpecZookeeperTolerations {
            effect?: string;
            key?: string;
            operator?: string;
            tolerationSeconds?: number;
            value?: string;
        }

        /**
         * The status of the Kafka and ZooKeeper clusters, and Topic Operator.
         */
        export interface KafkaStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaStatusConditions[];
            /**
             * Addresses of the internal and external listeners.
             */
            listeners?: outputs.kafka.v1beta1.KafkaStatusListeners[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
        }

        export interface KafkaStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        export interface KafkaStatusListeners {
            /**
             * A list of the addresses for this listener.
             */
            addresses?: outputs.kafka.v1beta1.KafkaStatusListenersAddresses[];
            /**
             * A comma-separated list of `host:port` pairs for connecting to the Kafka cluster using this listener.
             */
            bootstrapServers?: string;
            /**
             * A list of TLS certificates which can be used to verify the identity of the server when connecting to the given listener. Set only for `tls` and `external` listeners.
             */
            certificates?: string[];
            /**
             * The type of the listener. Can be one of the following three types: `plain`, `tls`, and `external`.
             */
            type?: string;
        }

        export interface KafkaStatusListenersAddresses {
            /**
             * The DNS name or IP address of the Kafka bootstrap service.
             */
            host?: string;
            /**
             * The port of the Kafka bootstrap service.
             */
            port?: number;
        }

        /**
         * The specification of the topic.
         */
        export interface KafkaTopicSpec {
            /**
             * The topic configuration.
             */
            config?: {[key: string]: any};
            /**
             * The number of partitions the topic should have. This cannot be decreased after topic creation. It can be increased after topic creation, but it is important to understand the consequences that has, especially for topics with semantic partitioning.
             */
            partitions: number;
            /**
             * The number of replicas the topic should have.
             */
            replicas: number;
            /**
             * The name of the topic. When absent this will default to the metadata.name of the topic. It is recommended to not set this unless the topic name is not a valid Kubernetes resource name.
             */
            topicName?: string;
        }

        /**
         * The status of the topic.
         */
        export interface KafkaTopicStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaTopicStatusConditions[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
        }

        export interface KafkaTopicStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }

        /**
         * The specification of the user.
         */
        export interface KafkaUserSpec {
            /**
             * Authentication mechanism enabled for this Kafka user.
             */
            authentication?: outputs.kafka.v1beta1.KafkaUserSpecAuthentication;
            /**
             * Authorization rules for this Kafka user.
             */
            authorization?: outputs.kafka.v1beta1.KafkaUserSpecAuthorization;
            /**
             * Quotas on requests to control the broker resources used by clients. Network bandwidth and request rate quotas can be enforced.Kafka documentation for Kafka User quotas can be found at http://kafka.apache.org/documentation/#design_quotas.
             */
            quotas?: outputs.kafka.v1beta1.KafkaUserSpecQuotas;
            /**
             * Template to specify how Kafka User `Secrets` are generated.
             */
            template?: outputs.kafka.v1beta1.KafkaUserSpecTemplate;
        }

        /**
         * Authentication mechanism enabled for this Kafka user.
         */
        export interface KafkaUserSpecAuthentication {
            /**
             * Authentication type.
             */
            type: string;
        }

        /**
         * Authorization rules for this Kafka user.
         */
        export interface KafkaUserSpecAuthorization {
            /**
             * List of ACL rules which should be applied to this user.
             */
            acls: outputs.kafka.v1beta1.KafkaUserSpecAuthorizationAcls[];
            /**
             * Authorization type. Currently the only supported type is `simple`. `simple` authorization type uses Kafka's `kafka.security.authorizer.AclAuthorizer` class for authorization.
             */
            type: string;
        }

        export interface KafkaUserSpecAuthorizationAcls {
            /**
             * The host from which the action described in the ACL rule is allowed or denied.
             */
            host?: string;
            /**
             * Operation which will be allowed or denied. Supported operations are: Read, Write, Create, Delete, Alter, Describe, ClusterAction, AlterConfigs, DescribeConfigs, IdempotentWrite and All.
             */
            operation: string;
            /**
             * Indicates the resource for which given ACL rule applies.
             */
            resource: outputs.kafka.v1beta1.KafkaUserSpecAuthorizationAclsResource;
            /**
             * The type of the rule. Currently the only supported type is `allow`. ACL rules with type `allow` are used to allow user to execute the specified operations. Default value is `allow`.
             */
            type?: string;
        }

        /**
         * Indicates the resource for which given ACL rule applies.
         */
        export interface KafkaUserSpecAuthorizationAclsResource {
            /**
             * Name of resource for which given ACL rule applies. Can be combined with `patternType` field to use prefix pattern.
             */
            name?: string;
            /**
             * Describes the pattern used in the resource field. The supported types are `literal` and `prefix`. With `literal` pattern type, the resource field will be used as a definition of a full name. With `prefix` pattern type, the resource name will be used only as a prefix. Default value is `literal`.
             */
            patternType?: string;
            /**
             * Resource type. The available resource types are `topic`, `group`, `cluster`, and `transactionalId`.
             */
            type: string;
        }

        /**
         * Quotas on requests to control the broker resources used by clients. Network bandwidth and request rate quotas can be enforced.Kafka documentation for Kafka User quotas can be found at http://kafka.apache.org/documentation/#design_quotas.
         */
        export interface KafkaUserSpecQuotas {
            /**
             * A quota on the maximum bytes per-second that each client group can fetch from a broker before the clients in the group are throttled. Defined on a per-broker basis.
             */
            consumerByteRate?: number;
            /**
             * A quota on the maximum bytes per-second that each client group can publish to a broker before the clients in the group are throttled. Defined on a per-broker basis.
             */
            producerByteRate?: number;
            /**
             * A quota on the maximum CPU utilization of each client group as a percentage of network and I/O threads.
             */
            requestPercentage?: number;
        }

        /**
         * Template to specify how Kafka User `Secrets` are generated.
         */
        export interface KafkaUserSpecTemplate {
            /**
             * Template for KafkaUser resources. The template allows users to specify how the `Secret` with password or TLS certificates is generated.
             */
            secret?: outputs.kafka.v1beta1.KafkaUserSpecTemplateSecret;
        }

        /**
         * Template for KafkaUser resources. The template allows users to specify how the `Secret` with password or TLS certificates is generated.
         */
        export interface KafkaUserSpecTemplateSecret {
            /**
             * Metadata applied to the resource.
             */
            metadata?: outputs.kafka.v1beta1.KafkaUserSpecTemplateSecretMetadata;
        }

        /**
         * Metadata applied to the resource.
         */
        export interface KafkaUserSpecTemplateSecretMetadata {
            /**
             * Annotations added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            annotations?: {[key: string]: any};
            /**
             * Labels added to the resource template. Can be applied to different resources such as `StatefulSets`, `Deployments`, `Pods`, and `Services`.
             */
            labels?: {[key: string]: any};
        }

        /**
         * The status of the Kafka User.
         */
        export interface KafkaUserStatus {
            /**
             * List of status conditions.
             */
            conditions?: outputs.kafka.v1beta1.KafkaUserStatusConditions[];
            /**
             * The generation of the CRD that was last reconciled by the operator.
             */
            observedGeneration?: number;
            /**
             * The name of `Secret` where the credentials are stored.
             */
            secret?: string;
            /**
             * Username.
             */
            username?: string;
        }

        export interface KafkaUserStatusConditions {
            /**
             * Last time the condition of a type changed from one status to another. The required format is 'yyyy-MM-ddTHH:mm:ssZ', in the UTC time zone.
             */
            lastTransitionTime?: string;
            /**
             * Human-readable message indicating details about the condition's last transition.
             */
            message?: string;
            /**
             * The reason for the condition's last transition (a single word in CamelCase).
             */
            reason?: string;
            /**
             * The status of the condition, either True, False or Unknown.
             */
            status?: string;
            /**
             * The unique identifier of a condition, used to distinguish between other conditions in the resource.
             */
            type?: string;
        }
    }
}
